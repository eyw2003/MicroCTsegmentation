{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71921c8",
   "metadata": {},
   "source": [
    "### Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334f76dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea764a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch.cuda\n",
    "import albumentations as albu\n",
    "import segmentation_models_pytorch as smp\n",
    "from  segmentation_models_pytorch.utils.base import Metric\n",
    "from segmentation_models_pytorch.base.modules import Activation\n",
    "from collections import defaultdict\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from Utils.dataset_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a449651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d51ae58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOLUMES_BASE_PATH=Path(r'G:\\Projects and Work\\Mouse Heart Segmentation\\Mice_CT_Dataset')\n",
    "LABELS_TO_KEEP=[1,600,420,550,205]\n",
    "SUBJECTS = [ 'C57-#10-MicroCT-020421 - Cardiac CT_110016-systole',\n",
    "            'C57-#9-MicroCT-020421 - Cardiac CT_105254-systole',\n",
    "            'C57-UmaControl#2-MicroCT-070120 - Cardiac CT_115916-diastole',\n",
    "            'C57-UmaControl#3-MicroCT-070120 - Cardiac CT_121937-systole',\n",
    "            'C57-#6-MicroCT-020421 - Cardiac CT_110734-systole',\n",
    "            'C57-#8-MicroCT-020421 - Cardiac CT_104450-systole',\n",
    "            'C57-UmaControl#1-MicroCT-070120 - Cardiac CT_115114-systole',\n",
    "            'C57-UmaControl#2-MicroCT-070120 - Cardiac CT_115916-systole',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb1c15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Axials', 'labels', 'volumes']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(VOLUMES_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12fadbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH=512\n",
    "HEIGHT=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef5b6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(data):\n",
    "#     data=(data-np.min(data))/(np.max(data)-np.min(data))\n",
    "#     return data\n",
    "# def load_volume(image_nifty_file, label_nifty_file):\n",
    "#     # load the image and label file, get the image content and return a numpy array for each\n",
    "#     label = None\n",
    "#     vol = (nib.load(image_nifty_file))\n",
    "#     image=np.array(vol.get_fdata())\n",
    "#     affine=vol.affine\n",
    "#     if os.path.exists(label_nifty_file):\n",
    "#         label = np.array(nib.load(label_nifty_file).get_fdata())\n",
    "#     return image, label,affine\n",
    "def convert_labels(label_volume):\n",
    "    new_labels=np.zeros(label_volume.shape)\n",
    "    for lbl in np.unique(label_volume):\n",
    "        if lbl in LABELS_TO_KEEP:\n",
    "            new_labels[np.where(label_volume==lbl)]=1\n",
    "    return new_labels\n",
    "\n",
    "def to_tensor(x, **kwargs): \n",
    "    x= torch.from_numpy(x.transpose(2, 0, 1).astype('float32'))\n",
    "    return x\n",
    "\n",
    "def create_folder(path):\n",
    "    if os.path.exists(path)==False:\n",
    "        os.mkdir(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9fbafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(model,img):\n",
    "    img=preprocessing_fn(img)\n",
    "    img=to_tensor(img)\n",
    "    img = img.to(device=DEVICE)\n",
    "    img=torch.unsqueeze(img,dim=0)\n",
    "    pred_mask=torch.squeeze(model(img))\n",
    "    pred_mask=pred_mask.detach().cpu().numpy()\n",
    "    return pred_mask\n",
    "def prepare_slice(img):\n",
    "    img=normalize(img)\n",
    "    img = img*255\n",
    "    img =img.astype('uint8')\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "    return img\n",
    "def predict_volume(model,volume,all_axials=False):\n",
    "    pred_vol=np.zeros(volume.shape)\n",
    "    out_Z=np.zeros(volume.shape)\n",
    "    if all_axials:\n",
    "        out_X=np.zeros(volume.shape)\n",
    "        out_Y=np.zeros(volume.shape)\n",
    "    X,Y,Z=volume.shape\n",
    "    for i in tqdm(range(Z)):\n",
    "        img = prepare_slice(volume[:,:,i])\n",
    "        pred_mask=predict_img(model,img)\n",
    "        out_Z[:,:,i]=pred_mask\n",
    "        \n",
    "    if all_axials:\n",
    "        for i in tqdm(range(Y)):\n",
    "            img = prepare_slice(volume[:,i,:])\n",
    "            pred_mask=predict_img(model,img)\n",
    "            out_Y[:,i,:]=pred_mask\n",
    "        for i in tqdm(range(X)):\n",
    "            img = prepare_slice(volume[i,:,:])\n",
    "            pred_mask=predict_img(model,img)\n",
    "            out_X[i,:,:]=pred_mask\n",
    "        pred_vol=(out_X+out_Y+out_Z)/3.0\n",
    "        pred_vol[pred_vol>0.5]=1\n",
    "        pred_vol[pred_vol<0.5]=0\n",
    "        return pred_vol\n",
    "    else:\n",
    "        return out_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfd99b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to choose\n",
    "ENCODER = 'resnet34'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "DEVICE = 'cuda'\n",
    "MODEL_NAME='UNET'\n",
    "BEST_WEIGHTS=r'G:\\Projects and Work\\Mouse Heart Segmentation\\Trained Weights - Mice\\imagenet\\Unet_resnet34\\best.pt'\n",
    "OUTPUT_PATH=Path(r'G:\\Projects and Work\\Mouse Heart Segmentation\\Trained Weights - Mice\\imagenet\\Unet_resnet34\\Outputs')\n",
    "create_folder(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd7efc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "best_model = torch.load(BEST_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "671296f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save numpy volume array to .nii\n",
    "def save_mask_nii(volume_arr,affine,path):\n",
    "    ni_img = nib.Nifti1Image(volume_arr,affine)\n",
    "    nib.save(ni_img, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8522f385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 512/512 [00:20<00:00, 24.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 512/512 [00:20<00:00, 25.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 512/512 [00:19<00:00, 26.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 512/512 [00:20<00:00, 25.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 512/512 [00:19<00:00, 25.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 512/512 [00:19<00:00, 25.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 512/512 [00:20<00:00, 25.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 512/512 [00:20<00:00, 25.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run a model on all volumes\n",
    "\n",
    "for i in range(len(SUBJECTS)):\n",
    "    subject_path = os.path.join(VOLUMES_BASE_PATH,'volumes',SUBJECTS[i],f'{SUBJECTS[i]}_volume.nii') # volume path\n",
    "    subject_label_path = os.path.join(VOLUMES_BASE_PATH,'labels',SUBJECTS[i],f'{SUBJECTS[i]}_label.nii') #volume label\n",
    "    if os.path.exists(subject_label_path)==False: # checking if extension is .nii or .nii.gz \n",
    "        subject_label_path = os.path.join(VOLUMES_BASE_PATH,'labels',SUBJECTS[i],f'{SUBJECTS[i]}_label.nii.gz')   \n",
    "    subject_name = SUBJECTS[i]\n",
    "    create_folder(os.path.join(OUTPUT_PATH,subject_name)) # create output folder\n",
    "    volume, volume_gt_mask,affine = load_case(subject_path,subject_label_path) # Load volume with its affine and mask\n",
    "#     volume_gt_mask=convert_labels(volume_gt_mask)\n",
    "    volume_pred_mask=predict_volume(best_model,volume,False)   # Predict volume\n",
    "    volume_pred_mask=np.round(volume_pred_mask)\n",
    "    save_mask_nii(volume_pred_mask,affine,os.path.join(OUTPUT_PATH,subject_name,'prediction_mask.nii.gz'))    #save predicted volume\n",
    "    if volume_gt_mask is not None:     # save grouth truth .nii file also for convinience\n",
    "        save_mask_nii(volume_gt_mask,affine,os.path.join(OUTPUT_PATH,subject_name,'ground_truth_mask.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e383de1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHAHER~1\\AppData\\Local\\Temp/ipykernel_14172/4222336267.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvolume_pred_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvolume\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgt_mask\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mvolume_gt_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvolume_pred_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image,cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "for i in range(10):\n",
    "    n = np.random.choice(volume_pred_mask.shape[2])\n",
    "    visualize(image=volume[:,:,n],gt_mask= volume_gt_mask[:,:,n],pred_mask=volume_pred_mask[:,:,n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556c204b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
