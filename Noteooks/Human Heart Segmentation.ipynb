{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f62cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch.cuda\n",
    "import albumentations as albu\n",
    "import segmentation_models_pytorch as smp\n",
    "from  segmentation_models_pytorch.utils.base import Metric\n",
    "from segmentation_models_pytorch.base.modules import Activation\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a14e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8bdb1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_2D_BASE_PATH=Path('G:\\ML Project Datasets\\Medical Image\\MM-WH 2017 Dataset\\Axials Version')\n",
    "WIDTH=320\n",
    "HEIGHT=320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f47e8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    all_images=os.listdir(path/'images')\n",
    "    all_masks=os.listdir(path/'masks')\n",
    "    \n",
    "    data = {'images':[],\n",
    "           'masks':[]}\n",
    "    for i in range(len(all_images)):\n",
    "        data['images'].append(str(path/'images'/all_images[i]))\n",
    "        data['masks'].append(str(path/'masks'/all_masks[i]))\n",
    "    return pd.DataFrame(data)\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95e3064a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "      <td>G:\\ML Project Datasets\\Medical Image\\MM-WH 201...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               images  \\\n",
       "0   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "1   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "2   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "3   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "4   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "5   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "6   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "7   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "8   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "9   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "10  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "11  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "12  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "13  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "14  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "15  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "16  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "17  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "18  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "19  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "20  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "21  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "22  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "23  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...   \n",
       "\n",
       "                                                masks  \n",
       "0   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "1   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "2   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "3   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "4   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "5   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "6   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "7   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "8   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "9   G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "10  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "11  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "12  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "13  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "14  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "15  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "16  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "17  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "18  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "19  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "20  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "21  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "22  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  \n",
       "23  G:\\ML Project Datasets\\Medical Image\\MM-WH 201...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=load_data(DATASET_2D_BASE_PATH/'train')[0:24]\n",
    "df_val=load_data(DATASET_2D_BASE_PATH/'val')[0:8]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c268cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset(BaseDataset):\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_path, \n",
    "            masks_path, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.images = images_path\n",
    "        self.masks = masks_path\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "#         print(self.images[i])\n",
    "        image = cv2.imread(str(self.images[i]))\n",
    "        mask = cv2.imread(self.masks[i],0)\n",
    "        mask=np.expand_dims(mask,axis=-1)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1c50cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "   \n",
    "        albu.Resize(HEIGHT,WIDTH),\n",
    "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.2,p=1, border_mode=cv2.BORDER_CONSTANT),\n",
    "        albu.RandomCrop(height=320, width=320, always_apply=True),\n",
    "        albu.Blur(blur_limit=3, p=0.4),\n",
    "        albu.GaussNoise(p=0.5),\n",
    "        albu.RandomBrightnessContrast(brightness_limit=0.3,contrast_limit=0.3,p=0.5),\n",
    "        albu.RandomBrightness(p=0.75)\n",
    "\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "def get_validation_augmentation():\n",
    "  \n",
    "    test_transform = [\n",
    "        albu.Resize(HEIGHT,WIDTH)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):  \n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b021bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "TRAIN_RUNS_PATH=r'G:\\Projects and Work\\Mouse Heart Segmentation\\runs'\n",
    "MODEL_NAME='Unet'\n",
    "BATCH_SIZE=8\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=1, \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6730c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\Projects and Work\\\\Mouse Heart Segmentation\\\\runs\\\\Unet_se_resnext50_32x4d'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHTS_PATH=os.path.join(TRAIN_RUNS_PATH,f'{MODEL_NAME}_{ENCODER}')\n",
    "WEIGHTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "53a0bfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [8, 64, 160, 160]           9,408\n",
      "       BatchNorm2d-2          [8, 64, 160, 160]             128\n",
      "              ReLU-3          [8, 64, 160, 160]               0\n",
      "         MaxPool2d-4            [8, 64, 80, 80]               0\n",
      "            Conv2d-5           [8, 128, 80, 80]           8,192\n",
      "       BatchNorm2d-6           [8, 128, 80, 80]             256\n",
      "              ReLU-7           [8, 128, 80, 80]               0\n",
      "            Conv2d-8           [8, 128, 80, 80]           4,608\n",
      "       BatchNorm2d-9           [8, 128, 80, 80]             256\n",
      "             ReLU-10           [8, 128, 80, 80]               0\n",
      "           Conv2d-11           [8, 256, 80, 80]          32,768\n",
      "      BatchNorm2d-12           [8, 256, 80, 80]             512\n",
      "           Conv2d-13           [8, 256, 80, 80]          16,384\n",
      "      BatchNorm2d-14           [8, 256, 80, 80]             512\n",
      "AdaptiveAvgPool2d-15             [8, 256, 1, 1]               0\n",
      "           Conv2d-16              [8, 16, 1, 1]           4,112\n",
      "             ReLU-17              [8, 16, 1, 1]               0\n",
      "           Conv2d-18             [8, 256, 1, 1]           4,352\n",
      "          Sigmoid-19             [8, 256, 1, 1]               0\n",
      "         SEModule-20           [8, 256, 80, 80]               0\n",
      "             ReLU-21           [8, 256, 80, 80]               0\n",
      "SEResNeXtBottleneck-22           [8, 256, 80, 80]               0\n",
      "           Conv2d-23           [8, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-24           [8, 128, 80, 80]             256\n",
      "             ReLU-25           [8, 128, 80, 80]               0\n",
      "           Conv2d-26           [8, 128, 80, 80]           4,608\n",
      "      BatchNorm2d-27           [8, 128, 80, 80]             256\n",
      "             ReLU-28           [8, 128, 80, 80]               0\n",
      "           Conv2d-29           [8, 256, 80, 80]          32,768\n",
      "      BatchNorm2d-30           [8, 256, 80, 80]             512\n",
      "AdaptiveAvgPool2d-31             [8, 256, 1, 1]               0\n",
      "           Conv2d-32              [8, 16, 1, 1]           4,112\n",
      "             ReLU-33              [8, 16, 1, 1]               0\n",
      "           Conv2d-34             [8, 256, 1, 1]           4,352\n",
      "          Sigmoid-35             [8, 256, 1, 1]               0\n",
      "         SEModule-36           [8, 256, 80, 80]               0\n",
      "             ReLU-37           [8, 256, 80, 80]               0\n",
      "SEResNeXtBottleneck-38           [8, 256, 80, 80]               0\n",
      "           Conv2d-39           [8, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-40           [8, 128, 80, 80]             256\n",
      "             ReLU-41           [8, 128, 80, 80]               0\n",
      "           Conv2d-42           [8, 128, 80, 80]           4,608\n",
      "      BatchNorm2d-43           [8, 128, 80, 80]             256\n",
      "             ReLU-44           [8, 128, 80, 80]               0\n",
      "           Conv2d-45           [8, 256, 80, 80]          32,768\n",
      "      BatchNorm2d-46           [8, 256, 80, 80]             512\n",
      "AdaptiveAvgPool2d-47             [8, 256, 1, 1]               0\n",
      "           Conv2d-48              [8, 16, 1, 1]           4,112\n",
      "             ReLU-49              [8, 16, 1, 1]               0\n",
      "           Conv2d-50             [8, 256, 1, 1]           4,352\n",
      "          Sigmoid-51             [8, 256, 1, 1]               0\n",
      "         SEModule-52           [8, 256, 80, 80]               0\n",
      "             ReLU-53           [8, 256, 80, 80]               0\n",
      "SEResNeXtBottleneck-54           [8, 256, 80, 80]               0\n",
      "           Conv2d-55           [8, 256, 80, 80]          65,536\n",
      "      BatchNorm2d-56           [8, 256, 80, 80]             512\n",
      "             ReLU-57           [8, 256, 80, 80]               0\n",
      "           Conv2d-58           [8, 256, 40, 40]          18,432\n",
      "      BatchNorm2d-59           [8, 256, 40, 40]             512\n",
      "             ReLU-60           [8, 256, 40, 40]               0\n",
      "           Conv2d-61           [8, 512, 40, 40]         131,072\n",
      "      BatchNorm2d-62           [8, 512, 40, 40]           1,024\n",
      "           Conv2d-63           [8, 512, 40, 40]         131,072\n",
      "      BatchNorm2d-64           [8, 512, 40, 40]           1,024\n",
      "AdaptiveAvgPool2d-65             [8, 512, 1, 1]               0\n",
      "           Conv2d-66              [8, 32, 1, 1]          16,416\n",
      "             ReLU-67              [8, 32, 1, 1]               0\n",
      "           Conv2d-68             [8, 512, 1, 1]          16,896\n",
      "          Sigmoid-69             [8, 512, 1, 1]               0\n",
      "         SEModule-70           [8, 512, 40, 40]               0\n",
      "             ReLU-71           [8, 512, 40, 40]               0\n",
      "SEResNeXtBottleneck-72           [8, 512, 40, 40]               0\n",
      "           Conv2d-73           [8, 256, 40, 40]         131,072\n",
      "      BatchNorm2d-74           [8, 256, 40, 40]             512\n",
      "             ReLU-75           [8, 256, 40, 40]               0\n",
      "           Conv2d-76           [8, 256, 40, 40]          18,432\n",
      "      BatchNorm2d-77           [8, 256, 40, 40]             512\n",
      "             ReLU-78           [8, 256, 40, 40]               0\n",
      "           Conv2d-79           [8, 512, 40, 40]         131,072\n",
      "      BatchNorm2d-80           [8, 512, 40, 40]           1,024\n",
      "AdaptiveAvgPool2d-81             [8, 512, 1, 1]               0\n",
      "           Conv2d-82              [8, 32, 1, 1]          16,416\n",
      "             ReLU-83              [8, 32, 1, 1]               0\n",
      "           Conv2d-84             [8, 512, 1, 1]          16,896\n",
      "          Sigmoid-85             [8, 512, 1, 1]               0\n",
      "         SEModule-86           [8, 512, 40, 40]               0\n",
      "             ReLU-87           [8, 512, 40, 40]               0\n",
      "SEResNeXtBottleneck-88           [8, 512, 40, 40]               0\n",
      "           Conv2d-89           [8, 256, 40, 40]         131,072\n",
      "      BatchNorm2d-90           [8, 256, 40, 40]             512\n",
      "             ReLU-91           [8, 256, 40, 40]               0\n",
      "           Conv2d-92           [8, 256, 40, 40]          18,432\n",
      "      BatchNorm2d-93           [8, 256, 40, 40]             512\n",
      "             ReLU-94           [8, 256, 40, 40]               0\n",
      "           Conv2d-95           [8, 512, 40, 40]         131,072\n",
      "      BatchNorm2d-96           [8, 512, 40, 40]           1,024\n",
      "AdaptiveAvgPool2d-97             [8, 512, 1, 1]               0\n",
      "           Conv2d-98              [8, 32, 1, 1]          16,416\n",
      "             ReLU-99              [8, 32, 1, 1]               0\n",
      "          Conv2d-100             [8, 512, 1, 1]          16,896\n",
      "         Sigmoid-101             [8, 512, 1, 1]               0\n",
      "        SEModule-102           [8, 512, 40, 40]               0\n",
      "            ReLU-103           [8, 512, 40, 40]               0\n",
      "SEResNeXtBottleneck-104           [8, 512, 40, 40]               0\n",
      "          Conv2d-105           [8, 256, 40, 40]         131,072\n",
      "     BatchNorm2d-106           [8, 256, 40, 40]             512\n",
      "            ReLU-107           [8, 256, 40, 40]               0\n",
      "          Conv2d-108           [8, 256, 40, 40]          18,432\n",
      "     BatchNorm2d-109           [8, 256, 40, 40]             512\n",
      "            ReLU-110           [8, 256, 40, 40]               0\n",
      "          Conv2d-111           [8, 512, 40, 40]         131,072\n",
      "     BatchNorm2d-112           [8, 512, 40, 40]           1,024\n",
      "AdaptiveAvgPool2d-113             [8, 512, 1, 1]               0\n",
      "          Conv2d-114              [8, 32, 1, 1]          16,416\n",
      "            ReLU-115              [8, 32, 1, 1]               0\n",
      "          Conv2d-116             [8, 512, 1, 1]          16,896\n",
      "         Sigmoid-117             [8, 512, 1, 1]               0\n",
      "        SEModule-118           [8, 512, 40, 40]               0\n",
      "            ReLU-119           [8, 512, 40, 40]               0\n",
      "SEResNeXtBottleneck-120           [8, 512, 40, 40]               0\n",
      "          Conv2d-121           [8, 512, 40, 40]         262,144\n",
      "     BatchNorm2d-122           [8, 512, 40, 40]           1,024\n",
      "            ReLU-123           [8, 512, 40, 40]               0\n",
      "          Conv2d-124           [8, 512, 20, 20]          73,728\n",
      "     BatchNorm2d-125           [8, 512, 20, 20]           1,024\n",
      "            ReLU-126           [8, 512, 20, 20]               0\n",
      "          Conv2d-127          [8, 1024, 20, 20]         524,288\n",
      "     BatchNorm2d-128          [8, 1024, 20, 20]           2,048\n",
      "          Conv2d-129          [8, 1024, 20, 20]         524,288\n",
      "     BatchNorm2d-130          [8, 1024, 20, 20]           2,048\n",
      "AdaptiveAvgPool2d-131            [8, 1024, 1, 1]               0\n",
      "          Conv2d-132              [8, 64, 1, 1]          65,600\n",
      "            ReLU-133              [8, 64, 1, 1]               0\n",
      "          Conv2d-134            [8, 1024, 1, 1]          66,560\n",
      "         Sigmoid-135            [8, 1024, 1, 1]               0\n",
      "        SEModule-136          [8, 1024, 20, 20]               0\n",
      "            ReLU-137          [8, 1024, 20, 20]               0\n",
      "SEResNeXtBottleneck-138          [8, 1024, 20, 20]               0\n",
      "          Conv2d-139           [8, 512, 20, 20]         524,288\n",
      "     BatchNorm2d-140           [8, 512, 20, 20]           1,024\n",
      "            ReLU-141           [8, 512, 20, 20]               0\n",
      "          Conv2d-142           [8, 512, 20, 20]          73,728\n",
      "     BatchNorm2d-143           [8, 512, 20, 20]           1,024\n",
      "            ReLU-144           [8, 512, 20, 20]               0\n",
      "          Conv2d-145          [8, 1024, 20, 20]         524,288\n",
      "     BatchNorm2d-146          [8, 1024, 20, 20]           2,048\n",
      "AdaptiveAvgPool2d-147            [8, 1024, 1, 1]               0\n",
      "          Conv2d-148              [8, 64, 1, 1]          65,600\n",
      "            ReLU-149              [8, 64, 1, 1]               0\n",
      "          Conv2d-150            [8, 1024, 1, 1]          66,560\n",
      "         Sigmoid-151            [8, 1024, 1, 1]               0\n",
      "        SEModule-152          [8, 1024, 20, 20]               0\n",
      "            ReLU-153          [8, 1024, 20, 20]               0\n",
      "SEResNeXtBottleneck-154          [8, 1024, 20, 20]               0\n",
      "          Conv2d-155           [8, 512, 20, 20]         524,288\n",
      "     BatchNorm2d-156           [8, 512, 20, 20]           1,024\n",
      "            ReLU-157           [8, 512, 20, 20]               0\n",
      "          Conv2d-158           [8, 512, 20, 20]          73,728\n",
      "     BatchNorm2d-159           [8, 512, 20, 20]           1,024\n",
      "            ReLU-160           [8, 512, 20, 20]               0\n",
      "          Conv2d-161          [8, 1024, 20, 20]         524,288\n",
      "     BatchNorm2d-162          [8, 1024, 20, 20]           2,048\n",
      "AdaptiveAvgPool2d-163            [8, 1024, 1, 1]               0\n",
      "          Conv2d-164              [8, 64, 1, 1]          65,600\n",
      "            ReLU-165              [8, 64, 1, 1]               0\n",
      "          Conv2d-166            [8, 1024, 1, 1]          66,560\n",
      "         Sigmoid-167            [8, 1024, 1, 1]               0\n",
      "        SEModule-168          [8, 1024, 20, 20]               0\n",
      "            ReLU-169          [8, 1024, 20, 20]               0\n",
      "SEResNeXtBottleneck-170          [8, 1024, 20, 20]               0\n",
      "          Conv2d-171           [8, 512, 20, 20]         524,288\n",
      "     BatchNorm2d-172           [8, 512, 20, 20]           1,024\n",
      "            ReLU-173           [8, 512, 20, 20]               0\n",
      "          Conv2d-174           [8, 512, 20, 20]          73,728\n",
      "     BatchNorm2d-175           [8, 512, 20, 20]           1,024\n",
      "            ReLU-176           [8, 512, 20, 20]               0\n",
      "          Conv2d-177          [8, 1024, 20, 20]         524,288\n",
      "     BatchNorm2d-178          [8, 1024, 20, 20]           2,048\n",
      "AdaptiveAvgPool2d-179            [8, 1024, 1, 1]               0\n",
      "          Conv2d-180              [8, 64, 1, 1]          65,600\n",
      "            ReLU-181              [8, 64, 1, 1]               0\n",
      "          Conv2d-182            [8, 1024, 1, 1]          66,560\n",
      "         Sigmoid-183            [8, 1024, 1, 1]               0\n",
      "        SEModule-184          [8, 1024, 20, 20]               0\n",
      "            ReLU-185          [8, 1024, 20, 20]               0\n",
      "SEResNeXtBottleneck-186          [8, 1024, 20, 20]               0\n",
      "          Conv2d-187           [8, 512, 20, 20]         524,288\n",
      "     BatchNorm2d-188           [8, 512, 20, 20]           1,024\n",
      "            ReLU-189           [8, 512, 20, 20]               0\n",
      "          Conv2d-190           [8, 512, 20, 20]          73,728\n",
      "     BatchNorm2d-191           [8, 512, 20, 20]           1,024\n",
      "            ReLU-192           [8, 512, 20, 20]               0\n",
      "          Conv2d-193          [8, 1024, 20, 20]         524,288\n",
      "     BatchNorm2d-194          [8, 1024, 20, 20]           2,048\n",
      "AdaptiveAvgPool2d-195            [8, 1024, 1, 1]               0\n",
      "          Conv2d-196              [8, 64, 1, 1]          65,600\n",
      "            ReLU-197              [8, 64, 1, 1]               0\n",
      "          Conv2d-198            [8, 1024, 1, 1]          66,560\n",
      "         Sigmoid-199            [8, 1024, 1, 1]               0\n",
      "        SEModule-200          [8, 1024, 20, 20]               0\n",
      "            ReLU-201          [8, 1024, 20, 20]               0\n",
      "SEResNeXtBottleneck-202          [8, 1024, 20, 20]               0\n",
      "          Conv2d-203           [8, 512, 20, 20]         524,288\n",
      "     BatchNorm2d-204           [8, 512, 20, 20]           1,024\n",
      "            ReLU-205           [8, 512, 20, 20]               0\n",
      "          Conv2d-206           [8, 512, 20, 20]          73,728\n",
      "     BatchNorm2d-207           [8, 512, 20, 20]           1,024\n",
      "            ReLU-208           [8, 512, 20, 20]               0\n",
      "          Conv2d-209          [8, 1024, 20, 20]         524,288\n",
      "     BatchNorm2d-210          [8, 1024, 20, 20]           2,048\n",
      "AdaptiveAvgPool2d-211            [8, 1024, 1, 1]               0\n",
      "          Conv2d-212              [8, 64, 1, 1]          65,600\n",
      "            ReLU-213              [8, 64, 1, 1]               0\n",
      "          Conv2d-214            [8, 1024, 1, 1]          66,560\n",
      "         Sigmoid-215            [8, 1024, 1, 1]               0\n",
      "        SEModule-216          [8, 1024, 20, 20]               0\n",
      "            ReLU-217          [8, 1024, 20, 20]               0\n",
      "SEResNeXtBottleneck-218          [8, 1024, 20, 20]               0\n",
      "          Conv2d-219          [8, 1024, 20, 20]       1,048,576\n",
      "     BatchNorm2d-220          [8, 1024, 20, 20]           2,048\n",
      "            ReLU-221          [8, 1024, 20, 20]               0\n",
      "          Conv2d-222          [8, 1024, 10, 10]         294,912\n",
      "     BatchNorm2d-223          [8, 1024, 10, 10]           2,048\n",
      "            ReLU-224          [8, 1024, 10, 10]               0\n",
      "          Conv2d-225          [8, 2048, 10, 10]       2,097,152\n",
      "     BatchNorm2d-226          [8, 2048, 10, 10]           4,096\n",
      "          Conv2d-227          [8, 2048, 10, 10]       2,097,152\n",
      "     BatchNorm2d-228          [8, 2048, 10, 10]           4,096\n",
      "AdaptiveAvgPool2d-229            [8, 2048, 1, 1]               0\n",
      "          Conv2d-230             [8, 128, 1, 1]         262,272\n",
      "            ReLU-231             [8, 128, 1, 1]               0\n",
      "          Conv2d-232            [8, 2048, 1, 1]         264,192\n",
      "         Sigmoid-233            [8, 2048, 1, 1]               0\n",
      "        SEModule-234          [8, 2048, 10, 10]               0\n",
      "            ReLU-235          [8, 2048, 10, 10]               0\n",
      "SEResNeXtBottleneck-236          [8, 2048, 10, 10]               0\n",
      "          Conv2d-237          [8, 1024, 10, 10]       2,097,152\n",
      "     BatchNorm2d-238          [8, 1024, 10, 10]           2,048\n",
      "            ReLU-239          [8, 1024, 10, 10]               0\n",
      "          Conv2d-240          [8, 1024, 10, 10]         294,912\n",
      "     BatchNorm2d-241          [8, 1024, 10, 10]           2,048\n",
      "            ReLU-242          [8, 1024, 10, 10]               0\n",
      "          Conv2d-243          [8, 2048, 10, 10]       2,097,152\n",
      "     BatchNorm2d-244          [8, 2048, 10, 10]           4,096\n",
      "AdaptiveAvgPool2d-245            [8, 2048, 1, 1]               0\n",
      "          Conv2d-246             [8, 128, 1, 1]         262,272\n",
      "            ReLU-247             [8, 128, 1, 1]               0\n",
      "          Conv2d-248            [8, 2048, 1, 1]         264,192\n",
      "         Sigmoid-249            [8, 2048, 1, 1]               0\n",
      "        SEModule-250          [8, 2048, 10, 10]               0\n",
      "            ReLU-251          [8, 2048, 10, 10]               0\n",
      "SEResNeXtBottleneck-252          [8, 2048, 10, 10]               0\n",
      "          Conv2d-253          [8, 1024, 10, 10]       2,097,152\n",
      "     BatchNorm2d-254          [8, 1024, 10, 10]           2,048\n",
      "            ReLU-255          [8, 1024, 10, 10]               0\n",
      "          Conv2d-256          [8, 1024, 10, 10]         294,912\n",
      "     BatchNorm2d-257          [8, 1024, 10, 10]           2,048\n",
      "            ReLU-258          [8, 1024, 10, 10]               0\n",
      "          Conv2d-259          [8, 2048, 10, 10]       2,097,152\n",
      "     BatchNorm2d-260          [8, 2048, 10, 10]           4,096\n",
      "AdaptiveAvgPool2d-261            [8, 2048, 1, 1]               0\n",
      "          Conv2d-262             [8, 128, 1, 1]         262,272\n",
      "            ReLU-263             [8, 128, 1, 1]               0\n",
      "          Conv2d-264            [8, 2048, 1, 1]         264,192\n",
      "         Sigmoid-265            [8, 2048, 1, 1]               0\n",
      "        SEModule-266          [8, 2048, 10, 10]               0\n",
      "            ReLU-267          [8, 2048, 10, 10]               0\n",
      "SEResNeXtBottleneck-268          [8, 2048, 10, 10]               0\n",
      "    SENetEncoder-269  [[-1, 3, 320, 320], [-1, 64, 160, 160], [-1, 256, 80, 80], [-1, 512, 40, 40], [-1, 1024, 20, 20], [-1, 2048, 10, 10]]               0\n",
      "        Identity-270          [8, 2048, 10, 10]               0\n",
      "        Identity-271          [8, 3072, 20, 20]               0\n",
      "       Attention-272          [8, 3072, 20, 20]               0\n",
      "          Conv2d-273           [8, 256, 20, 20]       7,077,888\n",
      "     BatchNorm2d-274           [8, 256, 20, 20]             512\n",
      "            ReLU-275           [8, 256, 20, 20]               0\n",
      "          Conv2d-276           [8, 256, 20, 20]         589,824\n",
      "     BatchNorm2d-277           [8, 256, 20, 20]             512\n",
      "            ReLU-278           [8, 256, 20, 20]               0\n",
      "        Identity-279           [8, 256, 20, 20]               0\n",
      "       Attention-280           [8, 256, 20, 20]               0\n",
      "    DecoderBlock-281           [8, 256, 20, 20]               0\n",
      "        Identity-282           [8, 768, 40, 40]               0\n",
      "       Attention-283           [8, 768, 40, 40]               0\n",
      "          Conv2d-284           [8, 128, 40, 40]         884,736\n",
      "     BatchNorm2d-285           [8, 128, 40, 40]             256\n",
      "            ReLU-286           [8, 128, 40, 40]               0\n",
      "          Conv2d-287           [8, 128, 40, 40]         147,456\n",
      "     BatchNorm2d-288           [8, 128, 40, 40]             256\n",
      "            ReLU-289           [8, 128, 40, 40]               0\n",
      "        Identity-290           [8, 128, 40, 40]               0\n",
      "       Attention-291           [8, 128, 40, 40]               0\n",
      "    DecoderBlock-292           [8, 128, 40, 40]               0\n",
      "        Identity-293           [8, 384, 80, 80]               0\n",
      "       Attention-294           [8, 384, 80, 80]               0\n",
      "          Conv2d-295            [8, 64, 80, 80]         221,184\n",
      "     BatchNorm2d-296            [8, 64, 80, 80]             128\n",
      "            ReLU-297            [8, 64, 80, 80]               0\n",
      "          Conv2d-298            [8, 64, 80, 80]          36,864\n",
      "     BatchNorm2d-299            [8, 64, 80, 80]             128\n",
      "            ReLU-300            [8, 64, 80, 80]               0\n",
      "        Identity-301            [8, 64, 80, 80]               0\n",
      "       Attention-302            [8, 64, 80, 80]               0\n",
      "    DecoderBlock-303            [8, 64, 80, 80]               0\n",
      "        Identity-304         [8, 128, 160, 160]               0\n",
      "       Attention-305         [8, 128, 160, 160]               0\n",
      "          Conv2d-306          [8, 32, 160, 160]          36,864\n",
      "     BatchNorm2d-307          [8, 32, 160, 160]              64\n",
      "            ReLU-308          [8, 32, 160, 160]               0\n",
      "          Conv2d-309          [8, 32, 160, 160]           9,216\n",
      "     BatchNorm2d-310          [8, 32, 160, 160]              64\n",
      "            ReLU-311          [8, 32, 160, 160]               0\n",
      "        Identity-312          [8, 32, 160, 160]               0\n",
      "       Attention-313          [8, 32, 160, 160]               0\n",
      "    DecoderBlock-314          [8, 32, 160, 160]               0\n",
      "          Conv2d-315          [8, 16, 320, 320]           4,608\n",
      "     BatchNorm2d-316          [8, 16, 320, 320]              32\n",
      "            ReLU-317          [8, 16, 320, 320]               0\n",
      "          Conv2d-318          [8, 16, 320, 320]           2,304\n",
      "     BatchNorm2d-319          [8, 16, 320, 320]              32\n",
      "            ReLU-320          [8, 16, 320, 320]               0\n",
      "        Identity-321          [8, 16, 320, 320]               0\n",
      "       Attention-322          [8, 16, 320, 320]               0\n",
      "    DecoderBlock-323          [8, 16, 320, 320]               0\n",
      "     UnetDecoder-324          [8, 16, 320, 320]               0\n",
      "          Conv2d-325           [8, 1, 320, 320]             145\n",
      "        Identity-326           [8, 1, 320, 320]               0\n",
      "         Sigmoid-327           [8, 1, 320, 320]               0\n",
      "      Activation-328           [8, 1, 320, 320]               0\n",
      "================================================================\n",
      "Total params: 34,523,969\n",
      "Trainable params: 34,523,969\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.38\n",
      "Forward/backward pass size (MB): 9477.88\n",
      "Params size (MB): 131.70\n",
      "Estimated Total Size (MB): 9618.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3,320,320), batch_size=BATCH_SIZE, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e24cc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCS(Metric):\n",
    "    __name__ = 'DCS'\n",
    "\n",
    "    def __init__(self, eps=0.00001, activation=None, ignore_channels=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "     \n",
    "        self.activation = Activation(activation)\n",
    "        self.ignore_channels = ignore_channels\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        y_pr = self.activation(y_pr)\n",
    "        dice_numerator = 2 * torch.sum(y_pr * y_gt) + self.eps\n",
    "        dice_denominator = torch.sum(y_pr) + torch.sum(y_gt) + self.eps\n",
    "        dice_coefficient = dice_numerator / dice_denominator\n",
    "        return dice_coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ffc13578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\projects and work\\mouse heart segmentation\\venv\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1802: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(\n",
    "    df_train['images'], \n",
    "    df_train['masks'], \n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    df_val['images'], \n",
    "    df_val['masks'], \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    ") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b292052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "    DCS()\n",
    "    \n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4b3687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8e680cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Directory G:\\Projects and Work\\Mouse Heart Segmentation\\runs\\Unet_se_resnext50_32x4d already exists\n"
     ]
    }
   ],
   "source": [
    "# train model for 100 epochs\n",
    "EPOCHS=10\n",
    "if os.path.exists(WEIGHTS_PATH)==False:\n",
    "    os.mkdir(WEIGHTS_PATH)\n",
    "else:\n",
    "    print(f\"Warning! Directory {WEIGHTS_PATH } already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9582a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 100%|████████████████████| 3/3 [00:01<00:00,  1.67it/s, dice_loss - 1.0, iou_score - 4.019e-13, DCS - 2.812e-11]\n",
      "valid: 100%|██████████████████| 8/8 [00:00<00:00, 29.60it/s, dice_loss - 0.9984, iou_score - 0.0008097, DCS - 0.001535]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|██████████████████████| 3/3 [00:01<00:00,  1.73it/s, dice_loss - 1.0, iou_score - 3.957e-13, DCS - 2.9e-11]\n",
      "valid: 100%|██████████████████| 8/8 [00:00<00:00, 29.02it/s, dice_loss - 0.9985, iou_score - 0.0008891, DCS - 0.001509]\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|█████████████████████| 3/3 [00:01<00:00,  1.66it/s, dice_loss - 1.0, iou_score - 4.14e-13, DCS - 2.923e-11]\n",
      "valid: 100%|██████████████████| 8/8 [00:00<00:00, 29.41it/s, dice_loss - 0.9985, iou_score - 0.0009557, DCS - 0.001523]\n",
      "\n",
      "Epoch: 3\n",
      "train: 100%|████████████████████| 3/3 [00:01<00:00,  1.64it/s, dice_loss - 1.0, iou_score - 4.412e-13, DCS - 2.939e-11]\n",
      "valid: 100%|███████████████████| 8/8 [00:00<00:00, 28.77it/s, dice_loss - 0.9984, iou_score - 0.001024, DCS - 0.001558]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 4\n",
      "train: 100%|█████████████████████| 3/3 [00:01<00:00,  1.68it/s, dice_loss - 1.0, iou_score - 4.58e-13, DCS - 3.006e-11]\n",
      "valid: 100%|███████████████████| 8/8 [00:00<00:00, 29.62it/s, dice_loss - 0.9984, iou_score - 0.001156, DCS - 0.001623]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 5\n",
      "train: 100%|████████████████████| 3/3 [00:01<00:00,  1.69it/s, dice_loss - 1.0, iou_score - 4.652e-13, DCS - 3.065e-11]\n",
      "valid: 100%|███████████████████| 8/8 [00:00<00:00, 29.41it/s, dice_loss - 0.9983, iou_score - 0.001247, DCS - 0.001679]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 6\n",
      "train: 100%|█████████████████████| 3/3 [00:01<00:00,  1.74it/s, dice_loss - 1.0, iou_score - 5.032e-13, DCS - 3.11e-11]\n",
      "valid: 100%|███████████████████| 8/8 [00:00<00:00, 28.87it/s, dice_loss - 0.9983, iou_score - 0.001251, DCS - 0.001679]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 7\n",
      "train: 100%|████████████████████| 3/3 [00:01<00:00,  1.71it/s, dice_loss - 1.0, iou_score - 5.186e-13, DCS - 3.167e-11]\n",
      "valid: 100%|███████████████████| 8/8 [00:00<00:00, 28.67it/s, dice_loss - 0.9984, iou_score - 0.001182, DCS - 0.001619]\n",
      "\n",
      "Epoch: 8\n",
      "train: 100%|████████████████████| 3/3 [00:01<00:00,  1.64it/s, dice_loss - 1.0, iou_score - 5.426e-13, DCS - 3.191e-11]\n",
      "valid: 100%|███████████████████| 8/8 [00:00<00:00, 28.87it/s, dice_loss - 0.9985, iou_score - 0.001036, DCS - 0.001505]\n",
      "\n",
      "Epoch: 9\n",
      "train: 100%|████████████████████| 3/3 [00:01<00:00,  1.64it/s, dice_loss - 1.0, iou_score - 5.747e-13, DCS - 3.207e-11]\n",
      "valid: 100%|██████████████████| 8/8 [00:00<00:00, 29.08it/s, dice_loss - 0.9986, iou_score - 0.0008548, DCS - 0.001396]\n"
     ]
    }
   ],
   "source": [
    "min_loss = 100000000\n",
    "train_history=defaultdict(list)\n",
    "valid_history=defaultdict(list)\n",
    "\n",
    "for i in range(0, EPOCHS):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if min_loss > valid_logs['dice_loss']:\n",
    "        min_loss = valid_logs['dice_loss']\n",
    "        torch.save(model, os.path.join(WEIGHTS_PATH,f'best_{str(i)}_{round(min_loss,4)}.pt'))\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')\n",
    "    # Maintain History\n",
    "    for log_key in train_logs.keys():\n",
    "        train_history[log_key].append(train_logs[log_key])\n",
    "        valid_history[log_key].append(valid_logs[log_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "54e41bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'dice_loss')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_history['dice_loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"dice_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "106ace7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(valid_history).to_csv(os.path.join(WEIGHTS_PATH,'validation_logs.csv'))\n",
    "pd.DataFrame(train_history).to_csv(os.path.join(WEIGHTS_PATH,'train_logs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c44ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
