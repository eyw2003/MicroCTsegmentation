{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f62cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch.cuda\n",
    "import albumentations as albu\n",
    "import segmentation_models_pytorch as smp\n",
    "from  segmentation_models_pytorch.utils.base import Metric\n",
    "from segmentation_models_pytorch.base.modules import Activation\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a14e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f47e8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    all_images=os.listdir(path/'images')\n",
    "    all_masks=os.listdir(path/'masks')\n",
    "    \n",
    "    data = {'images':[],\n",
    "           'masks':[]}\n",
    "    for i in range(len(all_images)):\n",
    "        data['images'].append(str(path/'images'/all_images[i]))\n",
    "        data['masks'].append(str(path/'masks'/all_masks[i]))\n",
    "    return pd.DataFrame(data)\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95911029",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_2D_BASE_PATH=Path(r'C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhammad\\Axials Version')\n",
    "WIDTH=320\n",
    "HEIGHT=320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95e3064a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20588</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20589</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20590</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20591</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20592</th>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "      <td>C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20593 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  images  \\\n",
       "0      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "1      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "2      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "3      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "4      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "...                                                  ...   \n",
       "20588  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "20589  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "20590  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "20591  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "20592  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...   \n",
       "\n",
       "                                                   masks  \n",
       "0      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "1      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "2      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "3      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "4      C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "...                                                  ...  \n",
       "20588  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "20589  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "20590  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "20591  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "20592  C:\\Users\\lm3088\\Documents\\POM-CTproject\\Muhamm...  \n",
       "\n",
       "[20593 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=load_data(DATASET_2D_BASE_PATH/'train')\n",
    "df_val=load_data(DATASET_2D_BASE_PATH/'val')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c268cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset(BaseDataset):\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_path, \n",
    "            masks_path, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.images = images_path\n",
    "        self.masks = masks_path\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "#         print(self.images[i])\n",
    "        image = cv2.imread(str(self.images[i]))\n",
    "        mask = cv2.imread(self.masks[i],0)\n",
    "        mask=np.expand_dims(mask,axis=-1)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1c50cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "   \n",
    "        albu.Resize(HEIGHT,WIDTH),\n",
    "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.2,p=1, border_mode=cv2.BORDER_CONSTANT),\n",
    "        albu.RandomCrop(height=320, width=320, always_apply=True),\n",
    "        albu.Blur(blur_limit=3, p=0.4),\n",
    "        albu.GaussNoise(p=0.5),\n",
    "        albu.RandomBrightnessContrast(brightness_limit=0.3,contrast_limit=0.3,p=0.5),\n",
    "        albu.RandomBrightness(p=0.75)\n",
    "\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "def get_validation_augmentation():\n",
    "  \n",
    "    test_transform = [\n",
    "        albu.Resize(HEIGHT,WIDTH)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):  \n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b021bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to C:\\Users\\lm3088/.cache\\torch\\hub\\checkpoints\\efficientnet-b4-6ed6700e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b228cada7a45d3b938f2a4a0a57846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/74.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ENCODER = 'efficientnet-b4' #'se_resnext50_32x4d' 'resnet101'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "TRAIN_RUNS_PATH=r'C:\\Users\\lm3088\\Documents\\GitHub\\MicroCTsegmentation\\runs'\n",
    "MODEL_NAME='Unet'\n",
    "BATCH_SIZE=32\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=1, \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6730c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lm3088\\\\Documents\\\\GitHub\\\\MicroCTsegmentation\\\\runs\\\\Unet_efficientnet-b4'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHTS_PATH=os.path.join(TRAIN_RUNS_PATH,f'{MODEL_NAME}_{ENCODER}')\n",
    "WEIGHTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53a0bfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         ZeroPad2d-1          [32, 3, 321, 321]               0\n",
      "Conv2dStaticSamePadding-2         [32, 48, 160, 160]           1,296\n",
      "       BatchNorm2d-3         [32, 48, 160, 160]              96\n",
      "MemoryEfficientSwish-4         [32, 48, 160, 160]               0\n",
      "         ZeroPad2d-5         [32, 48, 162, 162]               0\n",
      "Conv2dStaticSamePadding-6         [32, 48, 160, 160]             432\n",
      "       BatchNorm2d-7         [32, 48, 160, 160]              96\n",
      "MemoryEfficientSwish-8         [32, 48, 160, 160]               0\n",
      "          Identity-9             [32, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-10             [32, 12, 1, 1]             588\n",
      "MemoryEfficientSwish-11             [32, 12, 1, 1]               0\n",
      "         Identity-12             [32, 12, 1, 1]               0\n",
      "Conv2dStaticSamePadding-13             [32, 48, 1, 1]             624\n",
      "         Identity-14         [32, 48, 160, 160]               0\n",
      "Conv2dStaticSamePadding-15         [32, 24, 160, 160]           1,152\n",
      "      BatchNorm2d-16         [32, 24, 160, 160]              48\n",
      "      MBConvBlock-17         [32, 24, 160, 160]               0\n",
      "        ZeroPad2d-18         [32, 24, 162, 162]               0\n",
      "Conv2dStaticSamePadding-19         [32, 24, 160, 160]             216\n",
      "      BatchNorm2d-20         [32, 24, 160, 160]              48\n",
      "MemoryEfficientSwish-21         [32, 24, 160, 160]               0\n",
      "         Identity-22             [32, 24, 1, 1]               0\n",
      "Conv2dStaticSamePadding-23              [32, 6, 1, 1]             150\n",
      "MemoryEfficientSwish-24              [32, 6, 1, 1]               0\n",
      "         Identity-25              [32, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-26             [32, 24, 1, 1]             168\n",
      "         Identity-27         [32, 24, 160, 160]               0\n",
      "Conv2dStaticSamePadding-28         [32, 24, 160, 160]             576\n",
      "      BatchNorm2d-29         [32, 24, 160, 160]              48\n",
      "      MBConvBlock-30         [32, 24, 160, 160]               0\n",
      "         Identity-31         [32, 24, 160, 160]               0\n",
      "Conv2dStaticSamePadding-32        [32, 144, 160, 160]           3,456\n",
      "      BatchNorm2d-33        [32, 144, 160, 160]             288\n",
      "MemoryEfficientSwish-34        [32, 144, 160, 160]               0\n",
      "        ZeroPad2d-35        [32, 144, 161, 161]               0\n",
      "Conv2dStaticSamePadding-36          [32, 144, 80, 80]           1,296\n",
      "      BatchNorm2d-37          [32, 144, 80, 80]             288\n",
      "MemoryEfficientSwish-38          [32, 144, 80, 80]               0\n",
      "         Identity-39            [32, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-40              [32, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-41              [32, 6, 1, 1]               0\n",
      "         Identity-42              [32, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-43            [32, 144, 1, 1]           1,008\n",
      "         Identity-44          [32, 144, 80, 80]               0\n",
      "Conv2dStaticSamePadding-45           [32, 32, 80, 80]           4,608\n",
      "      BatchNorm2d-46           [32, 32, 80, 80]              64\n",
      "      MBConvBlock-47           [32, 32, 80, 80]               0\n",
      "         Identity-48           [32, 32, 80, 80]               0\n",
      "Conv2dStaticSamePadding-49          [32, 192, 80, 80]           6,144\n",
      "      BatchNorm2d-50          [32, 192, 80, 80]             384\n",
      "MemoryEfficientSwish-51          [32, 192, 80, 80]               0\n",
      "        ZeroPad2d-52          [32, 192, 82, 82]               0\n",
      "Conv2dStaticSamePadding-53          [32, 192, 80, 80]           1,728\n",
      "      BatchNorm2d-54          [32, 192, 80, 80]             384\n",
      "MemoryEfficientSwish-55          [32, 192, 80, 80]               0\n",
      "         Identity-56            [32, 192, 1, 1]               0\n",
      "Conv2dStaticSamePadding-57              [32, 8, 1, 1]           1,544\n",
      "MemoryEfficientSwish-58              [32, 8, 1, 1]               0\n",
      "         Identity-59              [32, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-60            [32, 192, 1, 1]           1,728\n",
      "         Identity-61          [32, 192, 80, 80]               0\n",
      "Conv2dStaticSamePadding-62           [32, 32, 80, 80]           6,144\n",
      "      BatchNorm2d-63           [32, 32, 80, 80]              64\n",
      "      MBConvBlock-64           [32, 32, 80, 80]               0\n",
      "         Identity-65           [32, 32, 80, 80]               0\n",
      "Conv2dStaticSamePadding-66          [32, 192, 80, 80]           6,144\n",
      "      BatchNorm2d-67          [32, 192, 80, 80]             384\n",
      "MemoryEfficientSwish-68          [32, 192, 80, 80]               0\n",
      "        ZeroPad2d-69          [32, 192, 82, 82]               0\n",
      "Conv2dStaticSamePadding-70          [32, 192, 80, 80]           1,728\n",
      "      BatchNorm2d-71          [32, 192, 80, 80]             384\n",
      "MemoryEfficientSwish-72          [32, 192, 80, 80]               0\n",
      "         Identity-73            [32, 192, 1, 1]               0\n",
      "Conv2dStaticSamePadding-74              [32, 8, 1, 1]           1,544\n",
      "MemoryEfficientSwish-75              [32, 8, 1, 1]               0\n",
      "         Identity-76              [32, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-77            [32, 192, 1, 1]           1,728\n",
      "         Identity-78          [32, 192, 80, 80]               0\n",
      "Conv2dStaticSamePadding-79           [32, 32, 80, 80]           6,144\n",
      "      BatchNorm2d-80           [32, 32, 80, 80]              64\n",
      "      MBConvBlock-81           [32, 32, 80, 80]               0\n",
      "         Identity-82           [32, 32, 80, 80]               0\n",
      "Conv2dStaticSamePadding-83          [32, 192, 80, 80]           6,144\n",
      "      BatchNorm2d-84          [32, 192, 80, 80]             384\n",
      "MemoryEfficientSwish-85          [32, 192, 80, 80]               0\n",
      "        ZeroPad2d-86          [32, 192, 82, 82]               0\n",
      "Conv2dStaticSamePadding-87          [32, 192, 80, 80]           1,728\n",
      "      BatchNorm2d-88          [32, 192, 80, 80]             384\n",
      "MemoryEfficientSwish-89          [32, 192, 80, 80]               0\n",
      "         Identity-90            [32, 192, 1, 1]               0\n",
      "Conv2dStaticSamePadding-91              [32, 8, 1, 1]           1,544\n",
      "MemoryEfficientSwish-92              [32, 8, 1, 1]               0\n",
      "         Identity-93              [32, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-94            [32, 192, 1, 1]           1,728\n",
      "         Identity-95          [32, 192, 80, 80]               0\n",
      "Conv2dStaticSamePadding-96           [32, 32, 80, 80]           6,144\n",
      "      BatchNorm2d-97           [32, 32, 80, 80]              64\n",
      "      MBConvBlock-98           [32, 32, 80, 80]               0\n",
      "         Identity-99           [32, 32, 80, 80]               0\n",
      "Conv2dStaticSamePadding-100          [32, 192, 80, 80]           6,144\n",
      "     BatchNorm2d-101          [32, 192, 80, 80]             384\n",
      "MemoryEfficientSwish-102          [32, 192, 80, 80]               0\n",
      "       ZeroPad2d-103          [32, 192, 83, 83]               0\n",
      "Conv2dStaticSamePadding-104          [32, 192, 40, 40]           4,800\n",
      "     BatchNorm2d-105          [32, 192, 40, 40]             384\n",
      "MemoryEfficientSwish-106          [32, 192, 40, 40]               0\n",
      "        Identity-107            [32, 192, 1, 1]               0\n",
      "Conv2dStaticSamePadding-108              [32, 8, 1, 1]           1,544\n",
      "MemoryEfficientSwish-109              [32, 8, 1, 1]               0\n",
      "        Identity-110              [32, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-111            [32, 192, 1, 1]           1,728\n",
      "        Identity-112          [32, 192, 40, 40]               0\n",
      "Conv2dStaticSamePadding-113           [32, 56, 40, 40]          10,752\n",
      "     BatchNorm2d-114           [32, 56, 40, 40]             112\n",
      "     MBConvBlock-115           [32, 56, 40, 40]               0\n",
      "        Identity-116           [32, 56, 40, 40]               0\n",
      "Conv2dStaticSamePadding-117          [32, 336, 40, 40]          18,816\n",
      "     BatchNorm2d-118          [32, 336, 40, 40]             672\n",
      "MemoryEfficientSwish-119          [32, 336, 40, 40]               0\n",
      "       ZeroPad2d-120          [32, 336, 44, 44]               0\n",
      "Conv2dStaticSamePadding-121          [32, 336, 40, 40]           8,400\n",
      "     BatchNorm2d-122          [32, 336, 40, 40]             672\n",
      "MemoryEfficientSwish-123          [32, 336, 40, 40]               0\n",
      "        Identity-124            [32, 336, 1, 1]               0\n",
      "Conv2dStaticSamePadding-125             [32, 14, 1, 1]           4,718\n",
      "MemoryEfficientSwish-126             [32, 14, 1, 1]               0\n",
      "        Identity-127             [32, 14, 1, 1]               0\n",
      "Conv2dStaticSamePadding-128            [32, 336, 1, 1]           5,040\n",
      "        Identity-129          [32, 336, 40, 40]               0\n",
      "Conv2dStaticSamePadding-130           [32, 56, 40, 40]          18,816\n",
      "     BatchNorm2d-131           [32, 56, 40, 40]             112\n",
      "     MBConvBlock-132           [32, 56, 40, 40]               0\n",
      "        Identity-133           [32, 56, 40, 40]               0\n",
      "Conv2dStaticSamePadding-134          [32, 336, 40, 40]          18,816\n",
      "     BatchNorm2d-135          [32, 336, 40, 40]             672\n",
      "MemoryEfficientSwish-136          [32, 336, 40, 40]               0\n",
      "       ZeroPad2d-137          [32, 336, 44, 44]               0\n",
      "Conv2dStaticSamePadding-138          [32, 336, 40, 40]           8,400\n",
      "     BatchNorm2d-139          [32, 336, 40, 40]             672\n",
      "MemoryEfficientSwish-140          [32, 336, 40, 40]               0\n",
      "        Identity-141            [32, 336, 1, 1]               0\n",
      "Conv2dStaticSamePadding-142             [32, 14, 1, 1]           4,718\n",
      "MemoryEfficientSwish-143             [32, 14, 1, 1]               0\n",
      "        Identity-144             [32, 14, 1, 1]               0\n",
      "Conv2dStaticSamePadding-145            [32, 336, 1, 1]           5,040\n",
      "        Identity-146          [32, 336, 40, 40]               0\n",
      "Conv2dStaticSamePadding-147           [32, 56, 40, 40]          18,816\n",
      "     BatchNorm2d-148           [32, 56, 40, 40]             112\n",
      "     MBConvBlock-149           [32, 56, 40, 40]               0\n",
      "        Identity-150           [32, 56, 40, 40]               0\n",
      "Conv2dStaticSamePadding-151          [32, 336, 40, 40]          18,816\n",
      "     BatchNorm2d-152          [32, 336, 40, 40]             672\n",
      "MemoryEfficientSwish-153          [32, 336, 40, 40]               0\n",
      "       ZeroPad2d-154          [32, 336, 44, 44]               0\n",
      "Conv2dStaticSamePadding-155          [32, 336, 40, 40]           8,400\n",
      "     BatchNorm2d-156          [32, 336, 40, 40]             672\n",
      "MemoryEfficientSwish-157          [32, 336, 40, 40]               0\n",
      "        Identity-158            [32, 336, 1, 1]               0\n",
      "Conv2dStaticSamePadding-159             [32, 14, 1, 1]           4,718\n",
      "MemoryEfficientSwish-160             [32, 14, 1, 1]               0\n",
      "        Identity-161             [32, 14, 1, 1]               0\n",
      "Conv2dStaticSamePadding-162            [32, 336, 1, 1]           5,040\n",
      "        Identity-163          [32, 336, 40, 40]               0\n",
      "Conv2dStaticSamePadding-164           [32, 56, 40, 40]          18,816\n",
      "     BatchNorm2d-165           [32, 56, 40, 40]             112\n",
      "     MBConvBlock-166           [32, 56, 40, 40]               0\n",
      "        Identity-167           [32, 56, 40, 40]               0\n",
      "Conv2dStaticSamePadding-168          [32, 336, 40, 40]          18,816\n",
      "     BatchNorm2d-169          [32, 336, 40, 40]             672\n",
      "MemoryEfficientSwish-170          [32, 336, 40, 40]               0\n",
      "       ZeroPad2d-171          [32, 336, 41, 41]               0\n",
      "Conv2dStaticSamePadding-172          [32, 336, 20, 20]           3,024\n",
      "     BatchNorm2d-173          [32, 336, 20, 20]             672\n",
      "MemoryEfficientSwish-174          [32, 336, 20, 20]               0\n",
      "        Identity-175            [32, 336, 1, 1]               0\n",
      "Conv2dStaticSamePadding-176             [32, 14, 1, 1]           4,718\n",
      "MemoryEfficientSwish-177             [32, 14, 1, 1]               0\n",
      "        Identity-178             [32, 14, 1, 1]               0\n",
      "Conv2dStaticSamePadding-179            [32, 336, 1, 1]           5,040\n",
      "        Identity-180          [32, 336, 20, 20]               0\n",
      "Conv2dStaticSamePadding-181          [32, 112, 20, 20]          37,632\n",
      "     BatchNorm2d-182          [32, 112, 20, 20]             224\n",
      "     MBConvBlock-183          [32, 112, 20, 20]               0\n",
      "        Identity-184          [32, 112, 20, 20]               0\n",
      "Conv2dStaticSamePadding-185          [32, 672, 20, 20]          75,264\n",
      "     BatchNorm2d-186          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-187          [32, 672, 20, 20]               0\n",
      "       ZeroPad2d-188          [32, 672, 22, 22]               0\n",
      "Conv2dStaticSamePadding-189          [32, 672, 20, 20]           6,048\n",
      "     BatchNorm2d-190          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-191          [32, 672, 20, 20]               0\n",
      "        Identity-192            [32, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-193             [32, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-194             [32, 28, 1, 1]               0\n",
      "        Identity-195             [32, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-196            [32, 672, 1, 1]          19,488\n",
      "        Identity-197          [32, 672, 20, 20]               0\n",
      "Conv2dStaticSamePadding-198          [32, 112, 20, 20]          75,264\n",
      "     BatchNorm2d-199          [32, 112, 20, 20]             224\n",
      "     MBConvBlock-200          [32, 112, 20, 20]               0\n",
      "        Identity-201          [32, 112, 20, 20]               0\n",
      "Conv2dStaticSamePadding-202          [32, 672, 20, 20]          75,264\n",
      "     BatchNorm2d-203          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-204          [32, 672, 20, 20]               0\n",
      "       ZeroPad2d-205          [32, 672, 22, 22]               0\n",
      "Conv2dStaticSamePadding-206          [32, 672, 20, 20]           6,048\n",
      "     BatchNorm2d-207          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-208          [32, 672, 20, 20]               0\n",
      "        Identity-209            [32, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-210             [32, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-211             [32, 28, 1, 1]               0\n",
      "        Identity-212             [32, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-213            [32, 672, 1, 1]          19,488\n",
      "        Identity-214          [32, 672, 20, 20]               0\n",
      "Conv2dStaticSamePadding-215          [32, 112, 20, 20]          75,264\n",
      "     BatchNorm2d-216          [32, 112, 20, 20]             224\n",
      "     MBConvBlock-217          [32, 112, 20, 20]               0\n",
      "        Identity-218          [32, 112, 20, 20]               0\n",
      "Conv2dStaticSamePadding-219          [32, 672, 20, 20]          75,264\n",
      "     BatchNorm2d-220          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-221          [32, 672, 20, 20]               0\n",
      "       ZeroPad2d-222          [32, 672, 22, 22]               0\n",
      "Conv2dStaticSamePadding-223          [32, 672, 20, 20]           6,048\n",
      "     BatchNorm2d-224          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-225          [32, 672, 20, 20]               0\n",
      "        Identity-226            [32, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-227             [32, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-228             [32, 28, 1, 1]               0\n",
      "        Identity-229             [32, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-230            [32, 672, 1, 1]          19,488\n",
      "        Identity-231          [32, 672, 20, 20]               0\n",
      "Conv2dStaticSamePadding-232          [32, 112, 20, 20]          75,264\n",
      "     BatchNorm2d-233          [32, 112, 20, 20]             224\n",
      "     MBConvBlock-234          [32, 112, 20, 20]               0\n",
      "        Identity-235          [32, 112, 20, 20]               0\n",
      "Conv2dStaticSamePadding-236          [32, 672, 20, 20]          75,264\n",
      "     BatchNorm2d-237          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-238          [32, 672, 20, 20]               0\n",
      "       ZeroPad2d-239          [32, 672, 22, 22]               0\n",
      "Conv2dStaticSamePadding-240          [32, 672, 20, 20]           6,048\n",
      "     BatchNorm2d-241          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-242          [32, 672, 20, 20]               0\n",
      "        Identity-243            [32, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-244             [32, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-245             [32, 28, 1, 1]               0\n",
      "        Identity-246             [32, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-247            [32, 672, 1, 1]          19,488\n",
      "        Identity-248          [32, 672, 20, 20]               0\n",
      "Conv2dStaticSamePadding-249          [32, 112, 20, 20]          75,264\n",
      "     BatchNorm2d-250          [32, 112, 20, 20]             224\n",
      "     MBConvBlock-251          [32, 112, 20, 20]               0\n",
      "        Identity-252          [32, 112, 20, 20]               0\n",
      "Conv2dStaticSamePadding-253          [32, 672, 20, 20]          75,264\n",
      "     BatchNorm2d-254          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-255          [32, 672, 20, 20]               0\n",
      "       ZeroPad2d-256          [32, 672, 22, 22]               0\n",
      "Conv2dStaticSamePadding-257          [32, 672, 20, 20]           6,048\n",
      "     BatchNorm2d-258          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-259          [32, 672, 20, 20]               0\n",
      "        Identity-260            [32, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-261             [32, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-262             [32, 28, 1, 1]               0\n",
      "        Identity-263             [32, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-264            [32, 672, 1, 1]          19,488\n",
      "        Identity-265          [32, 672, 20, 20]               0\n",
      "Conv2dStaticSamePadding-266          [32, 112, 20, 20]          75,264\n",
      "     BatchNorm2d-267          [32, 112, 20, 20]             224\n",
      "     MBConvBlock-268          [32, 112, 20, 20]               0\n",
      "        Identity-269          [32, 112, 20, 20]               0\n",
      "Conv2dStaticSamePadding-270          [32, 672, 20, 20]          75,264\n",
      "     BatchNorm2d-271          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-272          [32, 672, 20, 20]               0\n",
      "       ZeroPad2d-273          [32, 672, 24, 24]               0\n",
      "Conv2dStaticSamePadding-274          [32, 672, 20, 20]          16,800\n",
      "     BatchNorm2d-275          [32, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-276          [32, 672, 20, 20]               0\n",
      "        Identity-277            [32, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-278             [32, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-279             [32, 28, 1, 1]               0\n",
      "        Identity-280             [32, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-281            [32, 672, 1, 1]          19,488\n",
      "        Identity-282          [32, 672, 20, 20]               0\n",
      "Conv2dStaticSamePadding-283          [32, 160, 20, 20]         107,520\n",
      "     BatchNorm2d-284          [32, 160, 20, 20]             320\n",
      "     MBConvBlock-285          [32, 160, 20, 20]               0\n",
      "        Identity-286          [32, 160, 20, 20]               0\n",
      "Conv2dStaticSamePadding-287          [32, 960, 20, 20]         153,600\n",
      "     BatchNorm2d-288          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-289          [32, 960, 20, 20]               0\n",
      "       ZeroPad2d-290          [32, 960, 24, 24]               0\n",
      "Conv2dStaticSamePadding-291          [32, 960, 20, 20]          24,000\n",
      "     BatchNorm2d-292          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-293          [32, 960, 20, 20]               0\n",
      "        Identity-294            [32, 960, 1, 1]               0\n",
      "Conv2dStaticSamePadding-295             [32, 40, 1, 1]          38,440\n",
      "MemoryEfficientSwish-296             [32, 40, 1, 1]               0\n",
      "        Identity-297             [32, 40, 1, 1]               0\n",
      "Conv2dStaticSamePadding-298            [32, 960, 1, 1]          39,360\n",
      "        Identity-299          [32, 960, 20, 20]               0\n",
      "Conv2dStaticSamePadding-300          [32, 160, 20, 20]         153,600\n",
      "     BatchNorm2d-301          [32, 160, 20, 20]             320\n",
      "     MBConvBlock-302          [32, 160, 20, 20]               0\n",
      "        Identity-303          [32, 160, 20, 20]               0\n",
      "Conv2dStaticSamePadding-304          [32, 960, 20, 20]         153,600\n",
      "     BatchNorm2d-305          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-306          [32, 960, 20, 20]               0\n",
      "       ZeroPad2d-307          [32, 960, 24, 24]               0\n",
      "Conv2dStaticSamePadding-308          [32, 960, 20, 20]          24,000\n",
      "     BatchNorm2d-309          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-310          [32, 960, 20, 20]               0\n",
      "        Identity-311            [32, 960, 1, 1]               0\n",
      "Conv2dStaticSamePadding-312             [32, 40, 1, 1]          38,440\n",
      "MemoryEfficientSwish-313             [32, 40, 1, 1]               0\n",
      "        Identity-314             [32, 40, 1, 1]               0\n",
      "Conv2dStaticSamePadding-315            [32, 960, 1, 1]          39,360\n",
      "        Identity-316          [32, 960, 20, 20]               0\n",
      "Conv2dStaticSamePadding-317          [32, 160, 20, 20]         153,600\n",
      "     BatchNorm2d-318          [32, 160, 20, 20]             320\n",
      "     MBConvBlock-319          [32, 160, 20, 20]               0\n",
      "        Identity-320          [32, 160, 20, 20]               0\n",
      "Conv2dStaticSamePadding-321          [32, 960, 20, 20]         153,600\n",
      "     BatchNorm2d-322          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-323          [32, 960, 20, 20]               0\n",
      "       ZeroPad2d-324          [32, 960, 24, 24]               0\n",
      "Conv2dStaticSamePadding-325          [32, 960, 20, 20]          24,000\n",
      "     BatchNorm2d-326          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-327          [32, 960, 20, 20]               0\n",
      "        Identity-328            [32, 960, 1, 1]               0\n",
      "Conv2dStaticSamePadding-329             [32, 40, 1, 1]          38,440\n",
      "MemoryEfficientSwish-330             [32, 40, 1, 1]               0\n",
      "        Identity-331             [32, 40, 1, 1]               0\n",
      "Conv2dStaticSamePadding-332            [32, 960, 1, 1]          39,360\n",
      "        Identity-333          [32, 960, 20, 20]               0\n",
      "Conv2dStaticSamePadding-334          [32, 160, 20, 20]         153,600\n",
      "     BatchNorm2d-335          [32, 160, 20, 20]             320\n",
      "     MBConvBlock-336          [32, 160, 20, 20]               0\n",
      "        Identity-337          [32, 160, 20, 20]               0\n",
      "Conv2dStaticSamePadding-338          [32, 960, 20, 20]         153,600\n",
      "     BatchNorm2d-339          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-340          [32, 960, 20, 20]               0\n",
      "       ZeroPad2d-341          [32, 960, 24, 24]               0\n",
      "Conv2dStaticSamePadding-342          [32, 960, 20, 20]          24,000\n",
      "     BatchNorm2d-343          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-344          [32, 960, 20, 20]               0\n",
      "        Identity-345            [32, 960, 1, 1]               0\n",
      "Conv2dStaticSamePadding-346             [32, 40, 1, 1]          38,440\n",
      "MemoryEfficientSwish-347             [32, 40, 1, 1]               0\n",
      "        Identity-348             [32, 40, 1, 1]               0\n",
      "Conv2dStaticSamePadding-349            [32, 960, 1, 1]          39,360\n",
      "        Identity-350          [32, 960, 20, 20]               0\n",
      "Conv2dStaticSamePadding-351          [32, 160, 20, 20]         153,600\n",
      "     BatchNorm2d-352          [32, 160, 20, 20]             320\n",
      "     MBConvBlock-353          [32, 160, 20, 20]               0\n",
      "        Identity-354          [32, 160, 20, 20]               0\n",
      "Conv2dStaticSamePadding-355          [32, 960, 20, 20]         153,600\n",
      "     BatchNorm2d-356          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-357          [32, 960, 20, 20]               0\n",
      "       ZeroPad2d-358          [32, 960, 24, 24]               0\n",
      "Conv2dStaticSamePadding-359          [32, 960, 20, 20]          24,000\n",
      "     BatchNorm2d-360          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-361          [32, 960, 20, 20]               0\n",
      "        Identity-362            [32, 960, 1, 1]               0\n",
      "Conv2dStaticSamePadding-363             [32, 40, 1, 1]          38,440\n",
      "MemoryEfficientSwish-364             [32, 40, 1, 1]               0\n",
      "        Identity-365             [32, 40, 1, 1]               0\n",
      "Conv2dStaticSamePadding-366            [32, 960, 1, 1]          39,360\n",
      "        Identity-367          [32, 960, 20, 20]               0\n",
      "Conv2dStaticSamePadding-368          [32, 160, 20, 20]         153,600\n",
      "     BatchNorm2d-369          [32, 160, 20, 20]             320\n",
      "     MBConvBlock-370          [32, 160, 20, 20]               0\n",
      "        Identity-371          [32, 160, 20, 20]               0\n",
      "Conv2dStaticSamePadding-372          [32, 960, 20, 20]         153,600\n",
      "     BatchNorm2d-373          [32, 960, 20, 20]           1,920\n",
      "MemoryEfficientSwish-374          [32, 960, 20, 20]               0\n",
      "       ZeroPad2d-375          [32, 960, 23, 23]               0\n",
      "Conv2dStaticSamePadding-376          [32, 960, 10, 10]          24,000\n",
      "     BatchNorm2d-377          [32, 960, 10, 10]           1,920\n",
      "MemoryEfficientSwish-378          [32, 960, 10, 10]               0\n",
      "        Identity-379            [32, 960, 1, 1]               0\n",
      "Conv2dStaticSamePadding-380             [32, 40, 1, 1]          38,440\n",
      "MemoryEfficientSwish-381             [32, 40, 1, 1]               0\n",
      "        Identity-382             [32, 40, 1, 1]               0\n",
      "Conv2dStaticSamePadding-383            [32, 960, 1, 1]          39,360\n",
      "        Identity-384          [32, 960, 10, 10]               0\n",
      "Conv2dStaticSamePadding-385          [32, 272, 10, 10]         261,120\n",
      "     BatchNorm2d-386          [32, 272, 10, 10]             544\n",
      "     MBConvBlock-387          [32, 272, 10, 10]               0\n",
      "        Identity-388          [32, 272, 10, 10]               0\n",
      "Conv2dStaticSamePadding-389         [32, 1632, 10, 10]         443,904\n",
      "     BatchNorm2d-390         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-391         [32, 1632, 10, 10]               0\n",
      "       ZeroPad2d-392         [32, 1632, 14, 14]               0\n",
      "Conv2dStaticSamePadding-393         [32, 1632, 10, 10]          40,800\n",
      "     BatchNorm2d-394         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-395         [32, 1632, 10, 10]               0\n",
      "        Identity-396           [32, 1632, 1, 1]               0\n",
      "Conv2dStaticSamePadding-397             [32, 68, 1, 1]         111,044\n",
      "MemoryEfficientSwish-398             [32, 68, 1, 1]               0\n",
      "        Identity-399             [32, 68, 1, 1]               0\n",
      "Conv2dStaticSamePadding-400           [32, 1632, 1, 1]         112,608\n",
      "        Identity-401         [32, 1632, 10, 10]               0\n",
      "Conv2dStaticSamePadding-402          [32, 272, 10, 10]         443,904\n",
      "     BatchNorm2d-403          [32, 272, 10, 10]             544\n",
      "     MBConvBlock-404          [32, 272, 10, 10]               0\n",
      "        Identity-405          [32, 272, 10, 10]               0\n",
      "Conv2dStaticSamePadding-406         [32, 1632, 10, 10]         443,904\n",
      "     BatchNorm2d-407         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-408         [32, 1632, 10, 10]               0\n",
      "       ZeroPad2d-409         [32, 1632, 14, 14]               0\n",
      "Conv2dStaticSamePadding-410         [32, 1632, 10, 10]          40,800\n",
      "     BatchNorm2d-411         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-412         [32, 1632, 10, 10]               0\n",
      "        Identity-413           [32, 1632, 1, 1]               0\n",
      "Conv2dStaticSamePadding-414             [32, 68, 1, 1]         111,044\n",
      "MemoryEfficientSwish-415             [32, 68, 1, 1]               0\n",
      "        Identity-416             [32, 68, 1, 1]               0\n",
      "Conv2dStaticSamePadding-417           [32, 1632, 1, 1]         112,608\n",
      "        Identity-418         [32, 1632, 10, 10]               0\n",
      "Conv2dStaticSamePadding-419          [32, 272, 10, 10]         443,904\n",
      "     BatchNorm2d-420          [32, 272, 10, 10]             544\n",
      "     MBConvBlock-421          [32, 272, 10, 10]               0\n",
      "        Identity-422          [32, 272, 10, 10]               0\n",
      "Conv2dStaticSamePadding-423         [32, 1632, 10, 10]         443,904\n",
      "     BatchNorm2d-424         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-425         [32, 1632, 10, 10]               0\n",
      "       ZeroPad2d-426         [32, 1632, 14, 14]               0\n",
      "Conv2dStaticSamePadding-427         [32, 1632, 10, 10]          40,800\n",
      "     BatchNorm2d-428         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-429         [32, 1632, 10, 10]               0\n",
      "        Identity-430           [32, 1632, 1, 1]               0\n",
      "Conv2dStaticSamePadding-431             [32, 68, 1, 1]         111,044\n",
      "MemoryEfficientSwish-432             [32, 68, 1, 1]               0\n",
      "        Identity-433             [32, 68, 1, 1]               0\n",
      "Conv2dStaticSamePadding-434           [32, 1632, 1, 1]         112,608\n",
      "        Identity-435         [32, 1632, 10, 10]               0\n",
      "Conv2dStaticSamePadding-436          [32, 272, 10, 10]         443,904\n",
      "     BatchNorm2d-437          [32, 272, 10, 10]             544\n",
      "     MBConvBlock-438          [32, 272, 10, 10]               0\n",
      "        Identity-439          [32, 272, 10, 10]               0\n",
      "Conv2dStaticSamePadding-440         [32, 1632, 10, 10]         443,904\n",
      "     BatchNorm2d-441         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-442         [32, 1632, 10, 10]               0\n",
      "       ZeroPad2d-443         [32, 1632, 14, 14]               0\n",
      "Conv2dStaticSamePadding-444         [32, 1632, 10, 10]          40,800\n",
      "     BatchNorm2d-445         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-446         [32, 1632, 10, 10]               0\n",
      "        Identity-447           [32, 1632, 1, 1]               0\n",
      "Conv2dStaticSamePadding-448             [32, 68, 1, 1]         111,044\n",
      "MemoryEfficientSwish-449             [32, 68, 1, 1]               0\n",
      "        Identity-450             [32, 68, 1, 1]               0\n",
      "Conv2dStaticSamePadding-451           [32, 1632, 1, 1]         112,608\n",
      "        Identity-452         [32, 1632, 10, 10]               0\n",
      "Conv2dStaticSamePadding-453          [32, 272, 10, 10]         443,904\n",
      "     BatchNorm2d-454          [32, 272, 10, 10]             544\n",
      "     MBConvBlock-455          [32, 272, 10, 10]               0\n",
      "        Identity-456          [32, 272, 10, 10]               0\n",
      "Conv2dStaticSamePadding-457         [32, 1632, 10, 10]         443,904\n",
      "     BatchNorm2d-458         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-459         [32, 1632, 10, 10]               0\n",
      "       ZeroPad2d-460         [32, 1632, 14, 14]               0\n",
      "Conv2dStaticSamePadding-461         [32, 1632, 10, 10]          40,800\n",
      "     BatchNorm2d-462         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-463         [32, 1632, 10, 10]               0\n",
      "        Identity-464           [32, 1632, 1, 1]               0\n",
      "Conv2dStaticSamePadding-465             [32, 68, 1, 1]         111,044\n",
      "MemoryEfficientSwish-466             [32, 68, 1, 1]               0\n",
      "        Identity-467             [32, 68, 1, 1]               0\n",
      "Conv2dStaticSamePadding-468           [32, 1632, 1, 1]         112,608\n",
      "        Identity-469         [32, 1632, 10, 10]               0\n",
      "Conv2dStaticSamePadding-470          [32, 272, 10, 10]         443,904\n",
      "     BatchNorm2d-471          [32, 272, 10, 10]             544\n",
      "     MBConvBlock-472          [32, 272, 10, 10]               0\n",
      "        Identity-473          [32, 272, 10, 10]               0\n",
      "Conv2dStaticSamePadding-474         [32, 1632, 10, 10]         443,904\n",
      "     BatchNorm2d-475         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-476         [32, 1632, 10, 10]               0\n",
      "       ZeroPad2d-477         [32, 1632, 14, 14]               0\n",
      "Conv2dStaticSamePadding-478         [32, 1632, 10, 10]          40,800\n",
      "     BatchNorm2d-479         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-480         [32, 1632, 10, 10]               0\n",
      "        Identity-481           [32, 1632, 1, 1]               0\n",
      "Conv2dStaticSamePadding-482             [32, 68, 1, 1]         111,044\n",
      "MemoryEfficientSwish-483             [32, 68, 1, 1]               0\n",
      "        Identity-484             [32, 68, 1, 1]               0\n",
      "Conv2dStaticSamePadding-485           [32, 1632, 1, 1]         112,608\n",
      "        Identity-486         [32, 1632, 10, 10]               0\n",
      "Conv2dStaticSamePadding-487          [32, 272, 10, 10]         443,904\n",
      "     BatchNorm2d-488          [32, 272, 10, 10]             544\n",
      "     MBConvBlock-489          [32, 272, 10, 10]               0\n",
      "        Identity-490          [32, 272, 10, 10]               0\n",
      "Conv2dStaticSamePadding-491         [32, 1632, 10, 10]         443,904\n",
      "     BatchNorm2d-492         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-493         [32, 1632, 10, 10]               0\n",
      "       ZeroPad2d-494         [32, 1632, 14, 14]               0\n",
      "Conv2dStaticSamePadding-495         [32, 1632, 10, 10]          40,800\n",
      "     BatchNorm2d-496         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-497         [32, 1632, 10, 10]               0\n",
      "        Identity-498           [32, 1632, 1, 1]               0\n",
      "Conv2dStaticSamePadding-499             [32, 68, 1, 1]         111,044\n",
      "MemoryEfficientSwish-500             [32, 68, 1, 1]               0\n",
      "        Identity-501             [32, 68, 1, 1]               0\n",
      "Conv2dStaticSamePadding-502           [32, 1632, 1, 1]         112,608\n",
      "        Identity-503         [32, 1632, 10, 10]               0\n",
      "Conv2dStaticSamePadding-504          [32, 272, 10, 10]         443,904\n",
      "     BatchNorm2d-505          [32, 272, 10, 10]             544\n",
      "     MBConvBlock-506          [32, 272, 10, 10]               0\n",
      "        Identity-507          [32, 272, 10, 10]               0\n",
      "Conv2dStaticSamePadding-508         [32, 1632, 10, 10]         443,904\n",
      "     BatchNorm2d-509         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-510         [32, 1632, 10, 10]               0\n",
      "       ZeroPad2d-511         [32, 1632, 12, 12]               0\n",
      "Conv2dStaticSamePadding-512         [32, 1632, 10, 10]          14,688\n",
      "     BatchNorm2d-513         [32, 1632, 10, 10]           3,264\n",
      "MemoryEfficientSwish-514         [32, 1632, 10, 10]               0\n",
      "        Identity-515           [32, 1632, 1, 1]               0\n",
      "Conv2dStaticSamePadding-516             [32, 68, 1, 1]         111,044\n",
      "MemoryEfficientSwish-517             [32, 68, 1, 1]               0\n",
      "        Identity-518             [32, 68, 1, 1]               0\n",
      "Conv2dStaticSamePadding-519           [32, 1632, 1, 1]         112,608\n",
      "        Identity-520         [32, 1632, 10, 10]               0\n",
      "Conv2dStaticSamePadding-521          [32, 448, 10, 10]         731,136\n",
      "     BatchNorm2d-522          [32, 448, 10, 10]             896\n",
      "     MBConvBlock-523          [32, 448, 10, 10]               0\n",
      "        Identity-524          [32, 448, 10, 10]               0\n",
      "Conv2dStaticSamePadding-525         [32, 2688, 10, 10]       1,204,224\n",
      "     BatchNorm2d-526         [32, 2688, 10, 10]           5,376\n",
      "MemoryEfficientSwish-527         [32, 2688, 10, 10]               0\n",
      "       ZeroPad2d-528         [32, 2688, 12, 12]               0\n",
      "Conv2dStaticSamePadding-529         [32, 2688, 10, 10]          24,192\n",
      "     BatchNorm2d-530         [32, 2688, 10, 10]           5,376\n",
      "MemoryEfficientSwish-531         [32, 2688, 10, 10]               0\n",
      "        Identity-532           [32, 2688, 1, 1]               0\n",
      "Conv2dStaticSamePadding-533            [32, 112, 1, 1]         301,168\n",
      "MemoryEfficientSwish-534            [32, 112, 1, 1]               0\n",
      "        Identity-535            [32, 112, 1, 1]               0\n",
      "Conv2dStaticSamePadding-536           [32, 2688, 1, 1]         303,744\n",
      "        Identity-537         [32, 2688, 10, 10]               0\n",
      "Conv2dStaticSamePadding-538          [32, 448, 10, 10]       1,204,224\n",
      "     BatchNorm2d-539          [32, 448, 10, 10]             896\n",
      "     MBConvBlock-540          [32, 448, 10, 10]               0\n",
      "EfficientNetEncoder-541  [[-1, 3, 320, 320], [-1, 48, 160, 160], [-1, 32, 80, 80], [-1, 56, 40, 40], [-1, 160, 20, 20], [-1, 448, 10, 10]]               0\n",
      "        Identity-542          [32, 448, 10, 10]               0\n",
      "        Identity-543          [32, 608, 20, 20]               0\n",
      "       Attention-544          [32, 608, 20, 20]               0\n",
      "          Conv2d-545          [32, 256, 20, 20]       1,400,832\n",
      "     BatchNorm2d-546          [32, 256, 20, 20]             512\n",
      "            ReLU-547          [32, 256, 20, 20]               0\n",
      "          Conv2d-548          [32, 256, 20, 20]         589,824\n",
      "     BatchNorm2d-549          [32, 256, 20, 20]             512\n",
      "            ReLU-550          [32, 256, 20, 20]               0\n",
      "        Identity-551          [32, 256, 20, 20]               0\n",
      "       Attention-552          [32, 256, 20, 20]               0\n",
      "    DecoderBlock-553          [32, 256, 20, 20]               0\n",
      "        Identity-554          [32, 312, 40, 40]               0\n",
      "       Attention-555          [32, 312, 40, 40]               0\n",
      "          Conv2d-556          [32, 128, 40, 40]         359,424\n",
      "     BatchNorm2d-557          [32, 128, 40, 40]             256\n",
      "            ReLU-558          [32, 128, 40, 40]               0\n",
      "          Conv2d-559          [32, 128, 40, 40]         147,456\n",
      "     BatchNorm2d-560          [32, 128, 40, 40]             256\n",
      "            ReLU-561          [32, 128, 40, 40]               0\n",
      "        Identity-562          [32, 128, 40, 40]               0\n",
      "       Attention-563          [32, 128, 40, 40]               0\n",
      "    DecoderBlock-564          [32, 128, 40, 40]               0\n",
      "        Identity-565          [32, 160, 80, 80]               0\n",
      "       Attention-566          [32, 160, 80, 80]               0\n",
      "          Conv2d-567           [32, 64, 80, 80]          92,160\n",
      "     BatchNorm2d-568           [32, 64, 80, 80]             128\n",
      "            ReLU-569           [32, 64, 80, 80]               0\n",
      "          Conv2d-570           [32, 64, 80, 80]          36,864\n",
      "     BatchNorm2d-571           [32, 64, 80, 80]             128\n",
      "            ReLU-572           [32, 64, 80, 80]               0\n",
      "        Identity-573           [32, 64, 80, 80]               0\n",
      "       Attention-574           [32, 64, 80, 80]               0\n",
      "    DecoderBlock-575           [32, 64, 80, 80]               0\n",
      "        Identity-576        [32, 112, 160, 160]               0\n",
      "       Attention-577        [32, 112, 160, 160]               0\n",
      "          Conv2d-578         [32, 32, 160, 160]          32,256\n",
      "     BatchNorm2d-579         [32, 32, 160, 160]              64\n",
      "            ReLU-580         [32, 32, 160, 160]               0\n",
      "          Conv2d-581         [32, 32, 160, 160]           9,216\n",
      "     BatchNorm2d-582         [32, 32, 160, 160]              64\n",
      "            ReLU-583         [32, 32, 160, 160]               0\n",
      "        Identity-584         [32, 32, 160, 160]               0\n",
      "       Attention-585         [32, 32, 160, 160]               0\n",
      "    DecoderBlock-586         [32, 32, 160, 160]               0\n",
      "          Conv2d-587         [32, 16, 320, 320]           4,608\n",
      "     BatchNorm2d-588         [32, 16, 320, 320]              32\n",
      "            ReLU-589         [32, 16, 320, 320]               0\n",
      "          Conv2d-590         [32, 16, 320, 320]           2,304\n",
      "     BatchNorm2d-591         [32, 16, 320, 320]              32\n",
      "            ReLU-592         [32, 16, 320, 320]               0\n",
      "        Identity-593         [32, 16, 320, 320]               0\n",
      "       Attention-594         [32, 16, 320, 320]               0\n",
      "    DecoderBlock-595         [32, 16, 320, 320]               0\n",
      "     UnetDecoder-596         [32, 16, 320, 320]               0\n",
      "          Conv2d-597          [32, 1, 320, 320]             145\n",
      "        Identity-598          [32, 1, 320, 320]               0\n",
      "         Sigmoid-599          [32, 1, 320, 320]               0\n",
      "      Activation-600          [32, 1, 320, 320]               0\n",
      "================================================================\n",
      "Total params: 19,419,289\n",
      "Trainable params: 19,419,289\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 37.50\n",
      "Forward/backward pass size (MB): 11625.78\n",
      "Params size (MB): 74.08\n",
      "Estimated Total Size (MB): 11737.36\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lm3088\\Anaconda3\\envs\\venv\\lib\\site-packages\\torchsummary\\torchsummary.py:93: RuntimeWarning: overflow encountered in long_scalars\n",
      "  total_output += np.prod(summary[layer][\"output_shape\"])\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3,320,320), batch_size=BATCH_SIZE, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e24cc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCS(Metric):\n",
    "    __name__ = 'DCS'\n",
    "\n",
    "    def __init__(self, eps=0.00001, activation=None, ignore_channels=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "     \n",
    "        self.activation = Activation(activation)\n",
    "        self.ignore_channels = ignore_channels\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        y_pr = self.activation(y_pr)\n",
    "        dice_numerator = 2 * torch.sum(y_pr * y_gt) + self.eps\n",
    "        dice_denominator = torch.sum(y_pr) + torch.sum(y_gt) + self.eps\n",
    "        dice_coefficient = dice_numerator / dice_denominator\n",
    "        return dice_coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffc13578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lm3088\\Anaconda3\\envs\\venv\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1802: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(\n",
    "    df_train['images'], \n",
    "    df_train['masks'], \n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    df_val['images'], \n",
    "    df_val['masks'], \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    ") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b292052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "    DCS()\n",
    "    \n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4b3687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e680cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model for 125 epochs\n",
    "EPOCHS=125\n",
    "if os.path.exists(WEIGHTS_PATH)==False:\n",
    "    os.mkdir(WEIGHTS_PATH)\n",
    "else:\n",
    "    print(f\"Warning! Directory {WEIGHTS_PATH } already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9582a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:48<00:00,  3.63it/s, dice_loss - 0.2405, iou_score - 0.6989, DCS - 0.7595]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:19<00:00, 26.05it/s, dice_loss - 0.4701, iou_score - 0.8377, DCS - 0.5188]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.1061, iou_score - 0.8186, DCS - 0.8939]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:16<00:00, 26.37it/s, dice_loss - 0.3649, iou_score - 0.8623, DCS - 0.5424]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.66it/s, dice_loss - 0.08832, iou_score - 0.8434, DCS - 0.9117]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:11<00:00, 27.09it/s, dice_loss - 0.2536, iou_score - 0.8682, DCS - 0.5429]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 3\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.083, iou_score - 0.8542, DCS - 0.917]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:13<00:00, 26.86it/s, dice_loss - 0.1687, iou_score - 0.857, DCS - 0.5478]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 4\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.64it/s, dice_loss - 0.07972, iou_score - 0.8573, DCS - 0.9203]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:12<00:00, 27.00it/s, dice_loss - 0.1183, iou_score - 0.8682, DCS - 0.5439]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 5\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.07456, iou_score - 0.8677, DCS - 0.925]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:14<00:00, 26.64it/s, dice_loss - 0.1024, iou_score - 0.8686, DCS - 0.5546]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 6\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.65it/s, dice_loss - 0.0695, iou_score - 0.8739, DCS - 0.9302]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:12<00:00, 27.02it/s, dice_loss - 0.106, iou_score - 0.8692, DCS - 0.5575]\n",
      "\n",
      "Epoch: 7\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.65it/s, dice_loss - 0.07376, iou_score - 0.8687, DCS - 0.926]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:11<00:00, 27.14it/s, dice_loss - 0.1152, iou_score - 0.8437, DCS - 0.5464]\n",
      "\n",
      "Epoch: 8\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:41<00:00,  3.67it/s, dice_loss - 0.06838, iou_score - 0.877, DCS - 0.9313]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.79it/s, dice_loss - 0.08979, iou_score - 0.8735, DCS - 0.554]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 9\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:40<00:00,  3.68it/s, dice_loss - 0.06549, iou_score - 0.8816, DCS - 0.9338]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.68it/s, dice_loss - 0.09118, iou_score - 0.8702, DCS - 0.5498]\n",
      "\n",
      "Epoch: 10\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:41<00:00,  3.67it/s, dice_loss - 0.06494, iou_score - 0.882, DCS - 0.9348]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.63it/s, dice_loss - 0.08945, iou_score - 0.8705, DCS - 0.5549]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 11\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:43<00:00,  3.66it/s, dice_loss - 0.06514, iou_score - 0.8819, DCS - 0.9337]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:10<00:00, 27.22it/s, dice_loss - 0.08805, iou_score - 0.8703, DCS - 0.554]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 12\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:48<00:00,  3.64it/s, dice_loss - 0.06247, iou_score - 0.8861, DCS - 0.9355]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:10<00:00, 27.21it/s, dice_loss - 0.09213, iou_score - 0.8663, DCS - 0.5591]\n",
      "\n",
      "Epoch: 13\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.0604, iou_score - 0.8893, DCS - 0.9394]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:08<00:00, 27.56it/s, dice_loss - 0.08722, iou_score - 0.8709, DCS - 0.5553]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 14\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.65it/s, dice_loss - 0.05819, iou_score - 0.8934, DCS - 0.9408]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:11<00:00, 27.12it/s, dice_loss - 0.08584, iou_score - 0.8713, DCS - 0.5635]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 15\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.06147, iou_score - 0.8879, DCS - 0.9382]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:11<00:00, 27.10it/s, dice_loss - 0.08128, iou_score - 0.8761, DCS - 0.5584]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 16\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.0583, iou_score - 0.8927, DCS - 0.9394]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:11<00:00, 27.05it/s, dice_loss - 0.09381, iou_score - 0.8623, DCS - 0.5592]\n",
      "\n",
      "Epoch: 17\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.64it/s, dice_loss - 0.0567, iou_score - 0.8956, DCS - 0.9417]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:11<00:00, 27.07it/s, dice_loss - 0.08002, iou_score - 0.8774, DCS - 0.5611]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 18\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.05671, iou_score - 0.8952, DCS - 0.941]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:12<00:00, 26.94it/s, dice_loss - 0.07858, iou_score - 0.8783, DCS - 0.5812]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 19\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.05685, iou_score - 0.8956, DCS - 0.9424]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:08<00:00, 27.52it/s, dice_loss - 0.08343, iou_score - 0.8748, DCS - 0.5926]\n",
      "\n",
      "Epoch: 20\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:43<00:00,  3.66it/s, dice_loss - 0.05466, iou_score - 0.8986, DCS - 0.945]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.90it/s, dice_loss - 0.07822, iou_score - 0.8785, DCS - 0.5703]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 21\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:42<00:00,  3.67it/s, dice_loss - 0.05479, iou_score - 0.899, DCS - 0.943]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.78it/s, dice_loss - 0.07752, iou_score - 0.8805, DCS - 0.6008]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 22\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:41<00:00,  3.67it/s, dice_loss - 0.05166, iou_score - 0.9042, DCS - 0.9449]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:10<00:00, 27.32it/s, dice_loss - 0.08043, iou_score - 0.8766, DCS - 0.6172]\n",
      "\n",
      "Epoch: 23\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:43<00:00,  3.66it/s, dice_loss - 0.05014, iou_score - 0.9067, DCS - 0.9479]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.71it/s, dice_loss - 0.08207, iou_score - 0.8756, DCS - 0.6011]\n",
      "\n",
      "Epoch: 24\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.05102, iou_score - 0.9055, DCS - 0.9478]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:09<00:00, 27.41it/s, dice_loss - 0.08045, iou_score - 0.8771, DCS - 0.626]\n",
      "\n",
      "Epoch: 25\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:42<00:00,  3.66it/s, dice_loss - 0.05057, iou_score - 0.9057, DCS - 0.9487]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.78it/s, dice_loss - 0.08516, iou_score - 0.8706, DCS - 0.6236]\n",
      "Decrease decoder learning rate to 1e-5!\n",
      "\n",
      "Epoch: 26\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:43<00:00,  3.66it/s, dice_loss - 0.04852, iou_score - 0.9105, DCS - 0.9502]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.79it/s, dice_loss - 0.07808, iou_score - 0.8801, DCS - 0.6387]\n",
      "\n",
      "Epoch: 27\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.65it/s, dice_loss - 0.04713, iou_score - 0.9125, DCS - 0.9525]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:14<00:00, 26.70it/s, dice_loss - 0.0768, iou_score - 0.8815, DCS - 0.648]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 28\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.04555, iou_score - 0.9151, DCS - 0.9525]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:14<00:00, 26.75it/s, dice_loss - 0.07802, iou_score - 0.8803, DCS - 0.665]\n",
      "\n",
      "Epoch: 29\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.04493, iou_score - 0.9159, DCS - 0.9527]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:14<00:00, 26.65it/s, dice_loss - 0.07708, iou_score - 0.8814, DCS - 0.6621]\n",
      "\n",
      "Epoch: 30\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.045, iou_score - 0.916, DCS - 0.9538]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:14<00:00, 26.72it/s, dice_loss - 0.07679, iou_score - 0.8813, DCS - 0.7062]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 31\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:43<00:00,  3.66it/s, dice_loss - 0.04542, iou_score - 0.9151, DCS - 0.9542]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:05<00:00, 27.95it/s, dice_loss - 0.07774, iou_score - 0.8805, DCS - 0.6521]\n",
      "\n",
      "Epoch: 32\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:43<00:00,  3.66it/s, dice_loss - 0.04513, iou_score - 0.916, DCS - 0.9545]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:05<00:00, 27.98it/s, dice_loss - 0.07838, iou_score - 0.8798, DCS - 0.6158]\n",
      "\n",
      "Epoch: 33\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:40<00:00,  3.67it/s, dice_loss - 0.04363, iou_score - 0.9182, DCS - 0.9544]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:05<00:00, 28.01it/s, dice_loss - 0.07731, iou_score - 0.8811, DCS - 0.6516]\n",
      "\n",
      "Epoch: 34\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:42<00:00,  3.67it/s, dice_loss - 0.04351, iou_score - 0.9184, DCS - 0.955]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:05<00:00, 27.93it/s, dice_loss - 0.07844, iou_score - 0.8794, DCS - 0.6852]\n",
      "\n",
      "Epoch: 35\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:41<00:00,  3.67it/s, dice_loss - 0.04476, iou_score - 0.9168, DCS - 0.953]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:05<00:00, 27.98it/s, dice_loss - 0.07773, iou_score - 0.8804, DCS - 0.6864]\n",
      "\n",
      "Epoch: 36\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.65it/s, dice_loss - 0.04169, iou_score - 0.9213, DCS - 0.9571]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.78it/s, dice_loss - 0.07773, iou_score - 0.8804, DCS - 0.6857]\n",
      "\n",
      "Epoch: 37\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.66it/s, dice_loss - 0.04268, iou_score - 0.9202, DCS - 0.9562]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.83it/s, dice_loss - 0.07791, iou_score - 0.8803, DCS - 0.6488]\n",
      "\n",
      "Epoch: 38\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.66it/s, dice_loss - 0.0422, iou_score - 0.9205, DCS - 0.9574]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.82it/s, dice_loss - 0.07787, iou_score - 0.8804, DCS - 0.6611]\n",
      "\n",
      "Epoch: 39\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:43<00:00,  3.66it/s, dice_loss - 0.0415, iou_score - 0.9216, DCS - 0.9558]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.70it/s, dice_loss - 0.07855, iou_score - 0.8793, DCS - 0.6949]\n",
      "\n",
      "Epoch: 40\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:42<00:00,  3.67it/s, dice_loss - 0.0427, iou_score - 0.9198, DCS - 0.9558]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.80it/s, dice_loss - 0.07757, iou_score - 0.8808, DCS - 0.7055]\n",
      "\n",
      "Epoch: 41\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.65it/s, dice_loss - 0.04247, iou_score - 0.9208, DCS - 0.9559]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.85it/s, dice_loss - 0.07746, iou_score - 0.8802, DCS - 0.682]\n",
      "\n",
      "Epoch: 42\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.66it/s, dice_loss - 0.04255, iou_score - 0.9206, DCS - 0.9559]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.67it/s, dice_loss - 0.07756, iou_score - 0.8802, DCS - 0.6789]\n",
      "\n",
      "Epoch: 43\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.04153, iou_score - 0.9216, DCS - 0.9565]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.78it/s, dice_loss - 0.07858, iou_score - 0.8793, DCS - 0.6547]\n",
      "\n",
      "Epoch: 44\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.65it/s, dice_loss - 0.04175, iou_score - 0.9215, DCS - 0.9567]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.63it/s, dice_loss - 0.08128, iou_score - 0.8765, DCS - 0.6573]\n",
      "\n",
      "Epoch: 45\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:43<00:00,  3.66it/s, dice_loss - 0.04265, iou_score - 0.9206, DCS - 0.9569]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.76it/s, dice_loss - 0.0784, iou_score - 0.8791, DCS - 0.7226]\n",
      "\n",
      "Epoch: 46\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:44<00:00,  3.65it/s, dice_loss - 0.04197, iou_score - 0.9213, DCS - 0.9565]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.80it/s, dice_loss - 0.0779, iou_score - 0.8801, DCS - 0.6889]\n",
      "\n",
      "Epoch: 47\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.04073, iou_score - 0.9231, DCS - 0.957]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.81it/s, dice_loss - 0.07867, iou_score - 0.8791, DCS - 0.6536]\n",
      "\n",
      "Epoch: 48\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.04068, iou_score - 0.9231, DCS - 0.9582]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.74it/s, dice_loss - 0.07821, iou_score - 0.8799, DCS - 0.6396]\n",
      "\n",
      "Epoch: 49\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.04096, iou_score - 0.9226, DCS - 0.9581]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.73it/s, dice_loss - 0.07822, iou_score - 0.8793, DCS - 0.6811]\n",
      "\n",
      "Epoch: 50\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.04089, iou_score - 0.9234, DCS - 0.9575]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.72it/s, dice_loss - 0.0766, iou_score - 0.8813, DCS - 0.6831]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 51\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:45<00:00,  3.65it/s, dice_loss - 0.04189, iou_score - 0.9213, DCS - 0.9567]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.78it/s, dice_loss - 0.07663, iou_score - 0.8813, DCS - 0.6699]\n",
      "\n",
      "Epoch: 52\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:43<00:00,  3.66it/s, dice_loss - 0.04017, iou_score - 0.9241, DCS - 0.9587]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.75it/s, dice_loss - 0.07679, iou_score - 0.8814, DCS - 0.6882]\n",
      "\n",
      "Epoch: 53\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.64it/s, dice_loss - 0.04167, iou_score - 0.9224, DCS - 0.9561]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.74it/s, dice_loss - 0.08241, iou_score - 0.8756, DCS - 0.6812]\n",
      "\n",
      "Epoch: 54\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.65it/s, dice_loss - 0.04038, iou_score - 0.9245, DCS - 0.9577]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.70it/s, dice_loss - 0.07764, iou_score - 0.8805, DCS - 0.6429]\n",
      "\n",
      "Epoch: 55\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.64it/s, dice_loss - 0.03943, iou_score - 0.9256, DCS - 0.9579]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.76it/s, dice_loss - 0.07817, iou_score - 0.8796, DCS - 0.6925]\n",
      "\n",
      "Epoch: 56\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.65it/s, dice_loss - 0.04037, iou_score - 0.9241, DCS - 0.9596]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.77it/s, dice_loss - 0.07724, iou_score - 0.8807, DCS - 0.677]\n",
      "\n",
      "Epoch: 57\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:48<00:00,  3.64it/s, dice_loss - 0.0387, iou_score - 0.9266, DCS - 0.9605]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.77it/s, dice_loss - 0.07712, iou_score - 0.8811, DCS - 0.6677]\n",
      "\n",
      "Epoch: 58\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.65it/s, dice_loss - 0.03936, iou_score - 0.9258, DCS - 0.9587]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.75it/s, dice_loss - 0.0774, iou_score - 0.8808, DCS - 0.6771]\n",
      "\n",
      "Epoch: 59\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.03914, iou_score - 0.9259, DCS - 0.959]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.69it/s, dice_loss - 0.07786, iou_score - 0.8802, DCS - 0.6514]\n",
      "\n",
      "Epoch: 60\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:48<00:00,  3.63it/s, dice_loss - 0.03943, iou_score - 0.9258, DCS - 0.9572]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.78it/s, dice_loss - 0.07686, iou_score - 0.8814, DCS - 0.6977]\n",
      "\n",
      "Epoch: 61\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.04125, iou_score - 0.9237, DCS - 0.9575]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.77it/s, dice_loss - 0.07751, iou_score - 0.8806, DCS - 0.6756]\n",
      "\n",
      "Epoch: 62\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.03966, iou_score - 0.9254, DCS - 0.9573]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.77it/s, dice_loss - 0.07829, iou_score - 0.8797, DCS - 0.7306]\n",
      "\n",
      "Epoch: 63\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.0396, iou_score - 0.9253, DCS - 0.9591]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.81it/s, dice_loss - 0.07748, iou_score - 0.8808, DCS - 0.7373]\n",
      "\n",
      "Epoch: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.03899, iou_score - 0.9268, DCS - 0.9591]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.70it/s, dice_loss - 0.07823, iou_score - 0.8796, DCS - 0.6915]\n",
      "\n",
      "Epoch: 65\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:46<00:00,  3.64it/s, dice_loss - 0.03824, iou_score - 0.9276, DCS - 0.9602]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.81it/s, dice_loss - 0.07776, iou_score - 0.8803, DCS - 0.7065]\n",
      "\n",
      "Epoch: 66\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:48<00:00,  3.64it/s, dice_loss - 0.03901, iou_score - 0.9266, DCS - 0.9598]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.78it/s, dice_loss - 0.0759, iou_score - 0.8821, DCS - 0.6956]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 67\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:48<00:00,  3.63it/s, dice_loss - 0.04066, iou_score - 0.9247, DCS - 0.9586]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.72it/s, dice_loss - 0.07667, iou_score - 0.8814, DCS - 0.6679]\n",
      "\n",
      "Epoch: 68\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03917, iou_score - 0.9267, DCS - 0.9608]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.75it/s, dice_loss - 0.07724, iou_score - 0.8805, DCS - 0.6561]\n",
      "\n",
      "Epoch: 69\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:47<00:00,  3.64it/s, dice_loss - 0.03836, iou_score - 0.9276, DCS - 0.9594]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.71it/s, dice_loss - 0.07944, iou_score - 0.8788, DCS - 0.6534]\n",
      "\n",
      "Epoch: 70\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.0379, iou_score - 0.9285, DCS - 0.9606]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.77it/s, dice_loss - 0.07829, iou_score - 0.8796, DCS - 0.6831]\n",
      "\n",
      "Epoch: 71\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03789, iou_score - 0.9282, DCS - 0.9617]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.74it/s, dice_loss - 0.08152, iou_score - 0.8761, DCS - 0.709]\n",
      "\n",
      "Epoch: 72\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03805, iou_score - 0.9281, DCS - 0.9612]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.84it/s, dice_loss - 0.07865, iou_score - 0.8796, DCS - 0.6582]\n",
      "\n",
      "Epoch: 73\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03841, iou_score - 0.9283, DCS - 0.9603]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:13<00:00, 26.85it/s, dice_loss - 0.07813, iou_score - 0.8797, DCS - 0.6832]\n",
      "\n",
      "Epoch: 74\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03863, iou_score - 0.9273, DCS - 0.9593]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.69it/s, dice_loss - 0.07709, iou_score - 0.881, DCS - 0.6238]\n",
      "\n",
      "Epoch: 75\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03713, iou_score - 0.9296, DCS - 0.9613]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.80it/s, dice_loss - 0.07685, iou_score - 0.8812, DCS - 0.6326]\n",
      "\n",
      "Epoch: 76\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:50<00:00,  3.62it/s, dice_loss - 0.03858, iou_score - 0.9277, DCS - 0.9603]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.73it/s, dice_loss - 0.07697, iou_score - 0.8808, DCS - 0.615]\n",
      "\n",
      "Epoch: 77\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:52<00:00,  3.62it/s, dice_loss - 0.03776, iou_score - 0.9285, DCS - 0.9596]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.74it/s, dice_loss - 0.08012, iou_score - 0.8772, DCS - 0.6792]\n",
      "\n",
      "Epoch: 78\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:48<00:00,  3.63it/s, dice_loss - 0.03845, iou_score - 0.9279, DCS - 0.96]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.77it/s, dice_loss - 0.07915, iou_score - 0.8784, DCS - 0.6241]\n",
      "\n",
      "Epoch: 79\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03798, iou_score - 0.9285, DCS - 0.9613]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.63it/s, dice_loss - 0.07655, iou_score - 0.8815, DCS - 0.6792]\n",
      "\n",
      "Epoch: 80\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:48<00:00,  3.63it/s, dice_loss - 0.03738, iou_score - 0.9295, DCS - 0.9615]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.79it/s, dice_loss - 0.08197, iou_score - 0.8756, DCS - 0.6703]\n",
      "\n",
      "Epoch: 81\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:48<00:00,  3.63it/s, dice_loss - 0.0369, iou_score - 0.93, DCS - 0.9616]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.70it/s, dice_loss - 0.07962, iou_score - 0.8779, DCS - 0.6865]\n",
      "\n",
      "Epoch: 82\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.0376, iou_score - 0.9291, DCS - 0.9609]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.79it/s, dice_loss - 0.07836, iou_score - 0.8795, DCS - 0.6406]\n",
      "\n",
      "Epoch: 83\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:50<00:00,  3.62it/s, dice_loss - 0.03754, iou_score - 0.9293, DCS - 0.9613]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.74it/s, dice_loss - 0.07798, iou_score - 0.8802, DCS - 0.6361]\n",
      "\n",
      "Epoch: 84\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:50<00:00,  3.63it/s, dice_loss - 0.03697, iou_score - 0.9302, DCS - 0.9612]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.72it/s, dice_loss - 0.0781, iou_score - 0.8798, DCS - 0.6745]\n",
      "\n",
      "Epoch: 85\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:50<00:00,  3.62it/s, dice_loss - 0.03649, iou_score - 0.9305, DCS - 0.9624]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.81it/s, dice_loss - 0.07628, iou_score - 0.8815, DCS - 0.7009]\n",
      "\n",
      "Epoch: 86\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03655, iou_score - 0.9312, DCS - 0.9619]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.73it/s, dice_loss - 0.0773, iou_score - 0.8807, DCS - 0.7028]\n",
      "\n",
      "Epoch: 87\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03774, iou_score - 0.929, DCS - 0.9592]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.79it/s, dice_loss - 0.07832, iou_score - 0.8791, DCS - 0.7463]\n",
      "\n",
      "Epoch: 88\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03634, iou_score - 0.9311, DCS - 0.9611]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.76it/s, dice_loss - 0.07747, iou_score - 0.8807, DCS - 0.7107]\n",
      "\n",
      "Epoch: 89\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:50<00:00,  3.62it/s, dice_loss - 0.0361, iou_score - 0.9313, DCS - 0.962]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.68it/s, dice_loss - 0.07902, iou_score - 0.8789, DCS - 0.6611]\n",
      "\n",
      "Epoch: 90\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03588, iou_score - 0.9317, DCS - 0.9616]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.73it/s, dice_loss - 0.07815, iou_score - 0.8797, DCS - 0.6765]\n",
      "\n",
      "Epoch: 91\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03788, iou_score - 0.9289, DCS - 0.961]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.75it/s, dice_loss - 0.07831, iou_score - 0.8795, DCS - 0.637]\n",
      "\n",
      "Epoch: 92\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:52<00:00,  3.61it/s, dice_loss - 0.03658, iou_score - 0.9305, DCS - 0.9615]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.80it/s, dice_loss - 0.07722, iou_score - 0.8805, DCS - 0.6508]\n",
      "\n",
      "Epoch: 93\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:52<00:00,  3.61it/s, dice_loss - 0.03682, iou_score - 0.9309, DCS - 0.9628]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.71it/s, dice_loss - 0.07686, iou_score - 0.8809, DCS - 0.656]\n",
      "\n",
      "Epoch: 94\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:53<00:00,  3.61it/s, dice_loss - 0.03706, iou_score - 0.9301, DCS - 0.9619]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.69it/s, dice_loss - 0.07762, iou_score - 0.8804, DCS - 0.634]\n",
      "\n",
      "Epoch: 95\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:52<00:00,  3.62it/s, dice_loss - 0.03654, iou_score - 0.9312, DCS - 0.9612]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.82it/s, dice_loss - 0.07629, iou_score - 0.8817, DCS - 0.67]\n",
      "\n",
      "Epoch: 96\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:53<00:00,  3.61it/s, dice_loss - 0.03633, iou_score - 0.9312, DCS - 0.9622]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.85it/s, dice_loss - 0.07813, iou_score - 0.8795, DCS - 0.6534]\n",
      "\n",
      "Epoch: 97\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:52<00:00,  3.61it/s, dice_loss - 0.03689, iou_score - 0.9303, DCS - 0.9616]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.74it/s, dice_loss - 0.08024, iou_score - 0.8776, DCS - 0.624]\n",
      "\n",
      "Epoch: 98\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:50<00:00,  3.62it/s, dice_loss - 0.03618, iou_score - 0.9316, DCS - 0.9631]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.75it/s, dice_loss - 0.0808, iou_score - 0.8771, DCS - 0.6553]\n",
      "\n",
      "Epoch: 99\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:54<00:00,  3.61it/s, dice_loss - 0.03502, iou_score - 0.9332, DCS - 0.9635]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.73it/s, dice_loss - 0.07865, iou_score - 0.8788, DCS - 0.6615]\n",
      "\n",
      "Epoch: 100\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:54<00:00,  3.61it/s, dice_loss - 0.03633, iou_score - 0.9313, DCS - 0.9617]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.77it/s, dice_loss - 0.07887, iou_score - 0.879, DCS - 0.6027]\n",
      "\n",
      "Epoch: 101\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:53<00:00,  3.61it/s, dice_loss - 0.03647, iou_score - 0.9315, DCS - 0.9624]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.83it/s, dice_loss - 0.07884, iou_score - 0.879, DCS - 0.6911]\n",
      "\n",
      "Epoch: 102\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:53<00:00,  3.61it/s, dice_loss - 0.03511, iou_score - 0.9333, DCS - 0.9626]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.80it/s, dice_loss - 0.07839, iou_score - 0.8794, DCS - 0.6964]\n",
      "\n",
      "Epoch: 103\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:52<00:00,  3.61it/s, dice_loss - 0.03622, iou_score - 0.9318, DCS - 0.9615]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.81it/s, dice_loss - 0.07978, iou_score - 0.878, DCS - 0.6333]\n",
      "\n",
      "Epoch: 104\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:53<00:00,  3.61it/s, dice_loss - 0.03544, iou_score - 0.9326, DCS - 0.9634]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.76it/s, dice_loss - 0.0771, iou_score - 0.8806, DCS - 0.6688]\n",
      "\n",
      "Epoch: 105\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03563, iou_score - 0.9324, DCS - 0.9618]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.68it/s, dice_loss - 0.07794, iou_score - 0.8798, DCS - 0.6903]\n",
      "\n",
      "Epoch: 106\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03712, iou_score - 0.9306, DCS - 0.9621]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.81it/s, dice_loss - 0.07829, iou_score - 0.8794, DCS - 0.6298]\n",
      "\n",
      "Epoch: 107\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03496, iou_score - 0.9338, DCS - 0.9628]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.84it/s, dice_loss - 0.07705, iou_score - 0.8808, DCS - 0.6605]\n",
      "\n",
      "Epoch: 108\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:50<00:00,  3.62it/s, dice_loss - 0.03508, iou_score - 0.9334, DCS - 0.9638]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:09<00:00, 27.39it/s, dice_loss - 0.07817, iou_score - 0.8796, DCS - 0.684]\n",
      "\n",
      "Epoch: 109\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:53<00:00,  3.61it/s, dice_loss - 0.03645, iou_score - 0.9316, DCS - 0.9621]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.82it/s, dice_loss - 0.0778, iou_score - 0.8798, DCS - 0.6916]\n",
      "\n",
      "Epoch: 110\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03606, iou_score - 0.9318, DCS - 0.961]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.86it/s, dice_loss - 0.07886, iou_score - 0.879, DCS - 0.7212]\n",
      "\n",
      "Epoch: 111\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:50<00:00,  3.62it/s, dice_loss - 0.03526, iou_score - 0.9331, DCS - 0.9632]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.79it/s, dice_loss - 0.07845, iou_score - 0.8791, DCS - 0.6719]\n",
      "\n",
      "Epoch: 112\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03562, iou_score - 0.9327, DCS - 0.963]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.80it/s, dice_loss - 0.07802, iou_score - 0.8793, DCS - 0.6997]\n",
      "\n",
      "Epoch: 113\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03592, iou_score - 0.9323, DCS - 0.9637]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.68it/s, dice_loss - 0.07801, iou_score - 0.8795, DCS - 0.6722]\n",
      "\n",
      "Epoch: 114\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.0348, iou_score - 0.9339, DCS - 0.9633]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.69it/s, dice_loss - 0.07826, iou_score - 0.879, DCS - 0.7649]\n",
      "\n",
      "Epoch: 115\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03615, iou_score - 0.932, DCS - 0.9601]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.79it/s, dice_loss - 0.07999, iou_score - 0.8777, DCS - 0.6613]\n",
      "\n",
      "Epoch: 116\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03577, iou_score - 0.9323, DCS - 0.962]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.83it/s, dice_loss - 0.08122, iou_score - 0.876, DCS - 0.7143]\n",
      "\n",
      "Epoch: 117\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:49<00:00,  3.63it/s, dice_loss - 0.03574, iou_score - 0.9323, DCS - 0.9631]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.82it/s, dice_loss - 0.07942, iou_score - 0.8782, DCS - 0.6434]\n",
      "\n",
      "Epoch: 118\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03565, iou_score - 0.9332, DCS - 0.9637]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:08<00:00, 27.60it/s, dice_loss - 0.07913, iou_score - 0.8786, DCS - 0.6346]\n",
      "\n",
      "Epoch: 119\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03425, iou_score - 0.9348, DCS - 0.9646]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.75it/s, dice_loss - 0.07875, iou_score - 0.8789, DCS - 0.6664]\n",
      "\n",
      "Epoch: 120\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:53<00:00,  3.61it/s, dice_loss - 0.0352, iou_score - 0.9339, DCS - 0.963]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.83it/s, dice_loss - 0.08227, iou_score - 0.8753, DCS - 0.6876]\n",
      "\n",
      "Epoch: 121\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:52<00:00,  3.61it/s, dice_loss - 0.03499, iou_score - 0.9339, DCS - 0.9643]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.80it/s, dice_loss - 0.07928, iou_score - 0.8783, DCS - 0.6778]\n",
      "\n",
      "Epoch: 122\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03501, iou_score - 0.934, DCS - 0.9627]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.86it/s, dice_loss - 0.07781, iou_score - 0.8801, DCS - 0.6481]\n",
      "\n",
      "Epoch: 123\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:53<00:00,  3.61it/s, dice_loss - 0.03494, iou_score - 0.9342, DCS - 0.9631]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:07<00:00, 27.69it/s, dice_loss - 0.07718, iou_score - 0.8806, DCS - 0.726]\n",
      "\n",
      "Epoch: 124\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2575/2575 [11:51<00:00,  3.62it/s, dice_loss - 0.03411, iou_score - 0.9352, DCS - 0.9634]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5192/5192 [03:06<00:00, 27.77it/s, dice_loss - 0.07849, iou_score - 0.8789, DCS - 0.711]\n"
     ]
    }
   ],
   "source": [
    "min_loss = 100000000\n",
    "train_history=defaultdict(list)\n",
    "valid_history=defaultdict(list)\n",
    "\n",
    "for i in range(0, EPOCHS):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if min_loss > valid_logs['dice_loss']:\n",
    "        min_loss = valid_logs['dice_loss']\n",
    "        torch.save(model, os.path.join(WEIGHTS_PATH,f'best_{str(i)}_{round(min_loss,4)}.pt'))\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')\n",
    "    # Maintain History\n",
    "    for log_key in train_logs.keys():\n",
    "        train_history[log_key].append(train_logs[log_key])\n",
    "        valid_history[log_key].append(valid_logs[log_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54e41bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'dice_loss')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_history['dice_loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"dice_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "106ace7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(valid_history).to_csv(os.path.join(WEIGHTS_PATH,'validation_logs.csv'))\n",
    "pd.DataFrame(train_history).to_csv(os.path.join(WEIGHTS_PATH,'train_logs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c44ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
